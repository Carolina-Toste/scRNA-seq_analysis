---
title: "scRNA_seq_1st_Syk_chip"
author: "Carolina Toste"
date: "2023-12-04"
output: html_document
---


# Experiment details

Currently this is for the first batch of mice:

- 10 week old mice
- all males
- 3 treated (ERT) and 3 controls (APP)

The input data here is the output of Cogent Analyse (after having been demultiplexed)

Questions from Phil:

1. Did you look at Syk expression in the KO mice to: 
  - Exclude cells that still had Syk, which could dilute the effects of the WT vs KO comparison?
  - Compare between cells that had lost Syk and retained Syk within the same mouse for a paired internally controlled comparison (controls for cre dosage etc.)?
1. Did you look for DAM (disease associated microglia) and IFN microglia? These are 6-month APP mice, near enough, so presumably have some AD phenotype microglia, are these lost in the KO, and if not how is the Syk expression in them (ie. Are there cells that escape the KO)

## Overall summary

The spleen tyrosine kinase (SYK) plays a central role in microglia signalling, regulating important microglia functions. 
In addition, Syk interacts with identified AD risk genes such as TREM2 and PLCg2. 
In order to understand what is the role of Syk in microglia and how it can influence disease development we utilise a conditional knock-out (cKO) model of Syk in the APPNL-G-F mouse model of AD. 
Using tamoxifen delivered intraperitoneally (I.P.) to Syk x APP x Cre-ERT mice we can induce Cre dependent deletion of floxed Syk gene. Hence, this model allows us to induce cKO at different stages of disease development. 

Overall project aims (aim 4 is relevant here)

1. Validate the use of tamoxifen in Syk-Cre-Ert transgenic mice.
1. Establish the best dose of tamoxifen achieving highest cKO levels.
1. Find how long cKO lasts once induced at different ages.
1. Understand how cKO of SYK impacts microglia transcriptional profile on a single cell level (immediate vs long-term effects). --> The next experiment will involve mice where cKO was induced at 8 weeks and at 16 weeks and all were aged to 6 months. The idea is to compare how Syk influences microglia during disease progression and if absence of Syk at different stages can modify any disease relevant markers/functions.
1. Explore the functional impact of SYK cKO on microglia during disease progression. 

## Notes

- Pipeline adapted from code by Ruth Jones

- Samples `Syk_APP_M1` and `Syk_ERT_het_M1` seem to be poor quality. 
  - Remove them entirely or just filter based on total reads?
  - They cause errors with size factor calculations, removed them for now

- PCA/TSNE/UMAP don't cluster by treatment at all. There aren't any obvious clusters

TODO:

- add differential expression between syk cells (more than 5) and not
- update syk filter to just apply to knock-out samples

- check Ruths data for syk

- check similar length genes to see if they are similar - seq depth issue
- check genes detected with more than ~5 counts
- plot genes detected by sky count



```{r}
#| label: source packages needed
# load packages needed
source(here::here("scripts/setup.R"))
```

#Set-up folders

```{r}
# Set the path to the input folder and output folder
input_path <- "input/1st_Syk_chip/"
output_path <- "results/1st_Syk_chip/"
```

# Loading Data into R
```{r}
read_cogent <- function(input_path, file_pattern = "*_genematrix.csv") {
  # Get list of files
  files <- list.files(
    path = input_path,
    pattern = file_pattern,
    full.names = TRUE,
    recursive = TRUE
  )
  
  # Read in files
  files <- purrr::map(files, ~ readr::read_csv(.x, show_col_types = FALSE))
  
  return(files)
}
```

#Read in stats and gene_matrix
```{r}
# Read in stats files and filter rows where all numeric columns are 0
stats <- read_cogent(input_path = "input/1st_Syk_chip", file_pattern = "*_stats.csv") %>%
  purrr::map(~ dplyr::filter(.x, !if_all(where(is.numeric), ~ .x == 0)))

# Read in genematrix files
gene_matrix <- read_cogent(input_path = "input/1st_Syk_chip") 

# Select relevant columns from genematrix files based on barcodes in stats files
gene_matrix <- purrr::map2(stats, gene_matrix, ~ dplyr::select(.y, GeneID, contains(.x$Barcode))) %>%
  purrr::reduce(full_join, by = "GeneID")

```

#Merge stats list and get gene_info
```{r}
# Merge stats files
stats <- do.call(rbind, stats)

gene_info <- read_cogent(input_path = "input/1st_Syk_chip", file_pattern = "gene_info.csv") %>%
  # Remove duplicates
  unique()

gene_info <- as.data.frame(gene_info)

# Save objects as this can take a few seconds to run
write_csv(stats, "results/1st_Syk_chip/first_Syk_chip_stats.csv")
write_csv(gene_matrix, "results/1st_Syk_chip/first_Syk_chip_genematrix.csv")
write_csv(gene_info, "results/1st_Syk_chip/first_Syk_chip_gene_info.csv")
```

Because the fastq flies were not concatenated by chip, the current version of cogent (2.0) has produced a directory for each sample, but instead of each file only containing data for that sample, each file contains all barcodes, but the values are just 0 for other samples.

This results in conflicts if you try to merge the files as they are, so they need to be filtered to the respective sample data first.

For now, it seems best to first read in the stats files and filter out rows where all numeric columns are 0. 

This should leave only data from that sample, including the relevant barcodes.

These barcodes can them be used to select the relevant columns from the genematrix files (these can't just be filtered to all rows being 0, especially for the negative controls).

It takes a few seconds to read in all the gene matrix files, so I'll save the merged data to avoid re-runing this chunk.


#compute a percentage of total reads for each.

```{r}
# get numeric column names
#cols_to_compute <- dplyr::select(stats, where(is.numeric)) %>% names()
# note that one could change the code to select based on string if that would be more reliable
cols_to_compute <- dplyr::select(stats, contains("_Reads")) %>% names()


# calculate and add percentage of each read type
compute_percent <- function(df, column, read_col = "Barcoded_Reads") {
  # compute percent
  df <- data.frame((df[column] / df[read_col]) * 100)
  # new column name
  col <- paste0("percentage_", column)
  names(df) <- col
  return(df)
}

# compute columns and cbind them 
stats <- map_dfc(cols_to_compute, ~ compute_percent(stats, .x)) %>%
  # bind this new df to the og one
  cbind(stats, .)

rm(cols_to_compute)
```

#Add sample and control
```{r}
## Identify controls and samples
stats$sample_type <-
  ifelse(str_detect(string = stats$Sample, pattern = "Ctrl"),
         'Control',
         "Sample")

## add treatment col
stats$treatment <-
  ifelse(str_detect(string = stats$Sample, pattern = "ERT"),
         'Treated',
         "Control")

## if there are any undetected, short of undetermined reads, filter them
if (sum("Non_sample" %in% stats$Sample)) {
  ## check how many there are
  print(paste0(
    "There are ",
    sum(grepl("Non_sample", stats$Sample)),
    " non-sample reads"
  ))
  stats <- stats %>%
    dplyr::filter(Sample != "Non_sample")
}
```

# Cell and Feature QC

## SCE Object Annotation

- Numbers of cells sequenced for each sample based on your experimental conditions

```{r}
ggplot(data = stats, mapping = aes(x = Sample, fill = Sample)) + 
  geom_bar() +
  geom_text(aes(label = ..count..), stat = "count", vjust = 1.5, 
            colour = "black", size  = 3) +
  scale_fill_aaas(alpha = .7) + ylab(label = "Frequency") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 315, hjust = 0))
```

- Create the SingleCellExperiment Object, s4 data class [here for more info](http://bioconductor.org/books/3.15/OSCA.intro/the-singlecellexperiment-class.html)
  - Output will be a summary of the sce object dimensions (row x column), which equates to genes measured x sample \# (as a sanity check)

```{r}
#| label: make-sce

sce_all <- SingleCellExperiment(assays = list(counts = gene_matrix), colData = stats, rowData = gene_info) 
dim(sce_all)

saveRDS(sce_all, "results/1st_Syk_chip/SCE_all.rds")
rm(gene_info, gene_matrix, stats)
```

## Check Syk

The spleen tyrosine kinase (Syk) gene is knocked-out in this model.

Check counts of the Syk gene:

```{r}
#| label: check-syk

## filter to syk
sce_filt <- sce_all[grepl("Syk", rowData(sce_all)$Gene_Name),]

## get gene length for syk
syk_length <- rowData(sce_filt)$Gene_Length

df_syk <- as.data.frame(assay(sce_filt)) %>%
  rownames_to_column(var = "gene") %>%
  pivot_longer(-gene, names_to = "cell", values_to = "count")

## add sample and treatment
df_syk <- as.data.frame(colData(sce_filt)) %>%
  rownames_to_column(var = "cell") %>%
  dplyr::select(cell, Sample, treatment) %>%
  left_join(df_syk)

ggplot(df_syk, aes(Sample, count, fill = treatment)) +
  geom_violin() +
  ggtitle("Syk counts all")

## proportion of cell with 0 Syk
df_syk %>%
  group_by(Sample) %>%
  summarise(cell_num = n(), num_0s = sum(count == 0),
            count_0_proportion = (sum(count == 0) / n()) * 100,
            less_than_6_prop = (sum(count < 6) / n()) *100,
            less_than_11_prop = (sum(count < 11) / n()) *100,
            less_than_21_prop = (sum(count < 21) / n()) *100,
            more_than_50_prop = (sum(count > 50) / n()) *100) %>%
  DT::datatable()

## cells to keep based on syk count > 5
cells_to_exclude <- df_syk$cell[df_syk$count > 5]
write_rds(cells_to_exclude, "results/1st_Syk_chip/cells_to_exclude.rds")
#rm(df_syk, sce_filt)
```

The majority of cells have no Syk, but there are a few with high numbers.

```{r}

## check genes with similar length to syk
sce_filt_length <- sce_all[rowData(sce_all)$Gene_Length > 8500 & rowData(sce_all)$Gene_Length < 10500,]
sce_filt_length <- sce_all[rowData(sce_all)$Gene_Length > 10500,]
sce_filt_length$syk <- ifelse(rownames(colData(sce_filt_length)) %in% cells_to_exclude, "syk_present", "syk_absent")

df_syk <- as.data.frame(assay(sce_filt_length)) %>%
  rownames_to_column(var = "gene") %>%
  pivot_longer(-gene, names_to = "cell", values_to = "count")

## add sample and treatment
df_syk <- as.data.frame(colData(sce_filt_length)) %>%
  rownames_to_column(var = "cell") %>%
  dplyr::select(cell, Sample, treatment) %>%
  left_join(df_syk)

ggplot(df_syk, aes(Sample, count, fill = treatment)) +
  geom_violin() +
  ggtitle("Counts for genes with similar length to SYK")

df_syk %>% group_by(gene) %>% summarise(mean_count = mean(count), median_count = median(count))

```

- Remove Ryans data

```{r}
#| label: fil_ryan

sce_all <- sce_all[,!(colData(sce_all)$Sample %in% c("Plcg2_ki", "Plcg2_wt"))]
```

- Evaluate the number of genes detected in controls (called features in seq analysis)
  - Negative controls should have low numbers of genes detected, provides an estimate of background "noise".
  - Positive controls should have a mid-high number of genes detected, as K-562 cells are human lymphoblasts there will be fewer cells "detected" if aligned to the mouse genome, though some will be conserved between species.
  - If the controls aren't correct this suggests a technical issue with the library/sequencing.
  
So `Syk_APP_M1` and `Syk_ERT_het_M1` seem to have a large number of low reads.
The positive and negative controls seem to overlap a fair bit too, maybe a library issue?
The other samples are all above the negative control and so presumably should be fine

```{r}
#| label: all-gene-distr

plotColData(sce_all, x="Sample", y="Gene_Reads", colour_by = "Sample")+
  facet_grid(~ colData(sce_all)$sample_type, scales = "free_x", space = "free_x")+
  scale_y_log10()+
  theme(axis.text.x = element_text(angle=90))+
  ggtitle("Gene Reads")
```

- Restrict the genes to protein coding genes only (optional but recommended)

```{r}
#| label: make_pc

sce <- sce_all[rowData(sce_all)$Gene_Biotype == "protein_coding",]
dim(sce)
```

- Remove the data form the control samples

```{r}
#| label: fil_sample

sce <- sce[,colData(sce)$sample_type == "Sample"]
```

- Remove undetected genes (i.e. row count is 0) outputs the % of detected genes

```{r}
#| label: detected_genes

detected_genes <- rowSums(counts(sce)) > 0
sce <- sce[detected_genes,]
```

- `r (sum(detected_genes) / length(detected_genes))*100` % of genes are detected

- If needed you can also filter our sparsely expressed genes e.g. low levels detected in a small number of cells.
  - Uses the `addPerFeatureQC` function
  - Based on % of cells across the dataset in which gene has been detected
  - The maximum sparsity is based on 20 cells, in this case `r 1 - (20/ ncol(sce))`

```{r}
#| label: rm_sparse_genes

sce <- addPerFeatureQC(sce)
rowData(sce)$gene_sparsity <- (100 - rowData(sce)$detected) / 100
max.sparsity <- 1 - (20/ ncol(sce))
sparse.genes <- rowData(sce)$gene_sparsity > max.sparsity
sce <- sce[!sparse.genes,]
sum(sparse.genes)
rm (max.sparsity, detected_genes)
```

- Identify Mitochondrial and ribosomal genes, most specific way to do this is to add the Chromosome information from Ensemble database.
  - Selected [GRCm39v104](https://www.ncbi.nlm.nih.gov/grc/mouse) (now a later version, but this data aligned to v104)
  - **You will need to change the taxonomy for a human datasest**

```{r}
#| label: annotate_genes
#| cache: true

ah <- AnnotationHub()
# annotation hub caches the ensembl database on the machine, this is where you
# will need to alter the species and version.
ens.grcm38 <- query(ah, c("mus musculus", "EnsDb", 38))[[16]]

# Get the Chromosome number (SEQNAME) from the Ensembl database, and the
# Ensemble_ID which will be used to merge the two datasets.
genes <- rowData(sce)$Ensembl_ID
gene_annot <- AnnotationDbi::select(ens.grcm38, 
                                    keys = genes,
                                    keytype = "GENEID",
                                    columns = c("GENEID", "SEQNAME")) %>%
    set_names(c("Ensembl_ID", "Chromosome"))

# Identify missing Ensembl IDs
missing_genes <- anti_join(data.frame(Ensembl_ID = genes), gene_annot, by = "Ensembl_ID")

# Print the missing Ensembl IDs
print(missing_genes)

```

```{r}
# Load required libraries
library(biomaRt)

# Connect to the Ensembl database using the biomaRt package
ensembl <- useMart("ensembl", dataset = "mmusculus_gene_ensembl")


# Get the chromosome information for the missing Ensembl IDs directly from Ensembl
chromosome_info <- getBM(
  attributes = c("ensembl_gene_id", "chromosome_name"),
  filters = "ensembl_gene_id",
  values = missing_genes,
  mart = ensembl
)

# Print the chromosome information for the missing genes
print(chromosome_info)


```

```{r}
# Rename the columns in chromosome_info to match gene_annot
colnames(chromosome_info) <- c("Ensembl_ID", "Chromosome")

# Add the chromosome information as extra rows to gene_annot
gene_annot <- rbind(gene_annot, chromosome_info)

# Print the updated gene_annot data frame with chromosome information as extra rows
print(gene_annot)
```


```{r}
rowData(sce) <- merge(rowData(sce), gene_annot, by = "Ensembl_ID", sort=FALSE)
rownames(rowData(sce)) <- rowData(sce)$Ensembl_ID

#List the mitochondrial genes
is.mito <- which(rowData(sce)$Chromosome=="MT")

#Confirms mito gene number
length(is.mito)

#Add QC metrics to cells, including annotating mito genes
sce <- addPerCellQC(sce, subsets=list(Mito=is.mito))

rm(ah, ens.grcm38, genes, gene_annot, is.mito)
```

- Easiest way to do this (default), and also select ribosomal genes is to select genes with "mt", "Rpl or "Rps" in the name, the case is species dependent.

```{r}
#| label: annotate_genes_opt2

#^ indicates "starts with", these gene name patterns will differ in a human dataset 
mito_genes <- str_detect(string = rowData(sce)$Gene_Name, pattern = "^mt-")
ribo_genes <- str_detect(string = rowData(sce)$Gene_Name, pattern = "^Rpl|^Rps")


#Confirm numbers
sum(mito_genes, na.rm = TRUE)
sum(ribo_genes, na.rm = TRUE)
```

```{r}
mito_genes <- na.omit(mito_genes)
ribo_genes <- na.omit(ribo_genes)

# Calculate QC for cells
sce <- addPerCellQC(sce, subsets = list(ribo=ribo_genes))
                    
#rm(mito_genes, ribo_genes)
```

## Identification of low-quality cells

- Evaluate the number of genes detected (called features in seq analysis)
    - Negative controls should have low numbers of genes detected, provides an estimate of background "noise".
    - Positive controls should have a mid-high number of genes detected, as K-562 cells are human lymphoblasts there will be fewer cells "detected" if aligned to the mouse genome, though some will be conserved between species.
    - If the controls aren't correct this suggests a technical issue with the library/sequencing.

```{r}
#| label: geneDistr

plotColData(sce, x="Sample", y="detected", colour_by = "Sample")+
  scale_y_log10()+
  theme(axis.text.x = element_text(angle=90))+
  ggtitle("Detected Features")
```

- High numbers of mitochondrial or ribosomal reads indicate cells were dying at time of fixation
    - Cells with higher than \~5-10% mitochondrial would be considered for exclusion, though this is dependent on **your** dataset
    - Only high mito percentage used as a threshold in subsequent steps.

```{r}
#| label: mtDistr

plotColData(sce, x="Sample", y="subsets_Mito_percent", colour_by = "Sample")+
  theme(axis.text.x = element_text(angle=90))+
  ggtitle("Mito Percent")

plotColData(sce, x="Sample", y="subsets_ribo_percent", colour_by = "Sample")+
  theme(axis.text.x = element_text(angle=90))+
  ggtitle("Ribo Percent")

```
 
- Percentage of exon reads against the number of genes detected.

```{r}
#| label: perc_exon

plotColData(sce, x = "detected", y = "percentage_Exon_Reads", colour_by = "Sample") +
  theme(legend.position = "top",
        legend.direction = "horizontal",
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0)) +
  guides(colour = guide_legend(override.aes = list(size = 4)))
```

- Library complexity shows the relative proportion of the library size accounted for by the most highly expressed genes per cell.
- If a small number of highly expressed genes make up most of the library this is an indicator of low quality data, for an example look at the negative control.

```{r}
#| label: lib_complexity

plotScater(sce_all, block1 = "sample_type", colour_by = "Sample",
           nfeatures = 50, exprs_values = "counts", ncol = 3, line_width = .5) 

plotScater(sce, block1 = "sample_type", colour_by = "Sample",
           nfeatures = 50, exprs_values = "counts", ncol = 3, line_width = .5) 

rm(sce_all)
```

Overall, `Syk_APP_M1` and `Syk_ERT_het_M1` seem to be poor quality.
The other samples appear to be okay.

- The poor quality samples also cause errors further down - remove them for now

```{r}
## remove suspect samples
sce <- sce[,!(colData(sce)$Sample %in% c("Syk_APP_M1", "Syk_ERT_het_M1"))]
```

## Filtering of low-quality cells

- This step is more critical in other sc-seq types, e.g. droplet.
- Using the Scater function `quickPerCellQC` function, you can apply adaptive low library, low feature and high % mitochondrial thresholds to the entire dataset or on a per sample basis.
    - This uses the `isOutlier` function states (scran package) where anything outside of 3x median-absolute-deviations is marked as an outlier.
    - Per sample basis is recommended if your samples have a strong biological reason e.g. from different experiment days or different fixatives (if not required delete `batch=sce$sample`).
    - If you have bimodal data then this adaptive filtering would not be suitable.

```{r}
#| label: cell_qc

cell_qc_results <- quickPerCellQC(colData(sce),
                                  percent_subsets=c("subsets_Mito_percent"),
                                  batch=sce$Sample)

as.data.frame(cell_qc_results) %>% summarise(across(everything(), sum))

sce$low_lib_size <- cell_qc_results$low_lib_size
sce$low_n_features <- cell_qc_results$low_n_features
sce$high_mito_percent <- cell_qc_results$high_subsets_Mito_percent
sce$discard <- cell_qc_results$discard

#rm(cell_qc_results)
```

- Cells that are considered to be outliers in orange, do the thresholds look sensible?
  - You can also mark cells you suspect are outliers and remove them from analysis later e.g. in clustering.

```{r}
#| label: filtlib

plotColData(sce,
            x = "Sample",
            y = "sum",
            colour_by = "low_lib_size") +
  facet_grid( ~ colData(sce)$sample_type,
              scales = "free_x",
              space = "free_x") +
  scale_y_log10() +
  labs(y = "Total count", title = "Total count") +
  theme(axis.text.x = element_text(angle = 90)) +
  guides(colour = guide_legend(title = "Discarded"))
```

```{r}
#| label: filtGene

plotColData(sce, 
            x="Sample", 
            y="detected",
            colour_by = "low_n_features") + 
     facet_grid(~ colData(sce)$sample_type, scales = "free_x", space = "free_x") + 
    scale_y_log10() + 
    labs(y = "Genes detected", title = "Genes detected") +
    theme(axis.text.x = element_text(angle=90))+
    guides(colour=guide_legend(title="Discarded"))
```

```{r}
#| label: filtMT

plotColData(sce, 
        x="Sample", 
        y="subsets_Mito_percent",
        colour_by = "high_mito_percent") + 
     facet_grid(~ colData(sce)$sample_type, scales = "free_x", space = "free_x") + 
    labs(y = "Percentage mitochondrial",
         title = "Mitochondrial") +
    theme(axis.text.x = element_text(angle=90))+
    guides(colour=guide_legend(title="Discarded"))
```

- Remove the outliers from the dataset and re-calculate the cell QC metrics based on remainder.
  - You can edit which columns are removed if required.
  - To see the column names run `names(colData(sce))`.
  - The filtered file will then be saved.

```{r}
#| label: rm_outliers

sce <- sce[,!sce$discard]

#Remove the old QC metrics
colData(sce) <-
  colData(sce)[,!colnames(colData(sce)) %in% c("low_lib_size",
                                               "low_n_features",
                                               "high_mito_percent",
                                               "discard")]

#Rerun cellQC
sce<- addPerCellQC(sce)
```

- If you feel discrete cut-offs are more appropriate for your data exchange the first line of code in the chunk for this.
- *NOTE*: maybe should add a manual cut-off for total count ~1000?

#Added additional cut-off of No of genes > 1000

```{r}
sce <- sce[, sce$detected >= 1000] 


```


- Save filtered sce as an RDS (can be re-loaded later)

```{r}
#| label: RDS_genefil

saveRDS(sce, "results/1st_Syk_chip/filtered_genes.rds")
```
# Normalising counts

```{r}
#| label: readRDS
#| eval: false
#| include: false
 
sce <- readRDS("results/1st_Syk_chip/filtered_genes.rds")
```

- Needed due to differences in sequencing coverage, both technical (e.g. differences in PCR amplification) and biological. By removing technical differences it allows meaningful comparison of expression profiles between cells.
- CPM, TPM and DESeq size factor are common scaling normalisations not really suited for sparse sc-Seq data.
- Some normalisations developed for scSeq data [detailed descriptions](http://bioconductor.org/books/3.15/OSCA.basic/normalization.html).

## Deconvolution {.tabset}

- (Lun et al 2016)
  - Defines a pool of cells, sums the expression values from all pooled cells then normalise against an average reference. Computes a scaling factor.
  - This is repeated multiple times, cells are detected in multiple pools.
  - From this series of equations you can de-convolve pools to get scaling factors for each cell.
  - The min.mean is the scalar specifying the minimum average count of genes to be used for normalisation.

- Calculate `librarySizeFactors` (Scuttle) 
  - **#QUESTION** How does this work if library size factor is bimodal?
  - Per cell proportional to the library size so that the average size factor for each cell is one.
  - If the differential expression is unbalanced than this may not be an appropriate in normalising expression between clusters, though this analysis should have minimal impact on cluster separation and highly expressed marker genes.

```{r}
#| label: lib_sf

lib.sf <- librarySizeFactors(sce)
dd <- data.frame("log10libSf"=log10(lib.sf))
ggplot(dd, aes(x=log10libSf, fill = colData(sce)$Sample)) + 
  geom_histogram(bins=50, position = "identity", alpha = 0.5) +
      labs(y = "Frequency", x = "Library Size Factor (Log10)") +
    guides(fill=guide_legend(title="Sample"))
```

- Create a pool of cells by clustering, the number of cells per cluster are:\

```{r}
#| label: pooled_factors
#| eval: false

# Cluster cells by similarity, most  suited to 10x numbers
set.seed(100)
clust <- scran::quickCluster(sce) # stores which cluster each cell was assigned too.
table(clust) # summarises number of clusters and cells in each cluster
sce <- computePooledFactors(sce, clusters = clust, min.mean = 0.1) # computes size factors, referred to as computeSumFactors in scran package
deconv.sf <- sizeFactors(sce)
```

- Deconvolve this data and plot the library size factor against the deconvolved size factor, most should be a linear relationship.

```{r}
#| label: deconv_plot
#| eval: false

colData(sce)$cell_sparsity <- 1 - (colData(sce)$detected / nrow(sce))

deconvDf <- data.frame(lib.sf, deconv.sf,
                       "source_name" = sce$Sample,
                      "sum" = sce$sum,
                      "mito_content" = sce$subsets_Mito_percent,
                      "cell_sparsity" = sce$cell_sparsity)

ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=sce$Sample))+
  geom_point()

rm(dd, deconvDf, clust, deconv.sf, detected_genes, lib.sf)
```

- Apply these normalised values to your sce object using `scater::logNormCounts()`
- Save filtered sce as an RDS (can be re-loaded later)

```{r}
#| label: logNormCounts

sce <- logNormCounts(sce)
assays(sce)
saveRDS(sce, "results/1st_Syk_chip/normalised_Deconvolution.rds")
```
# Dimension Reduction Analysis

- Want to focus on biologically meaningful variation, one way to do this is to focus the PCA/clustering on the most highly variable genes.
    - For ease use common gene names instead of EnsembleID_GeneName format currently used, will add ".1" etc if any gene names aren't unique (optional).

```{r}
#| label: rowname_symbol

rownames(sce) <- uniquifyFeatureNames(rownames(sce), rowData(sce)$Gene_Name)
```

- `modelGeneVar` will help select the most variable genes based on the logcount data, assuming no spike-in controls, it will model the relationship between the mean and the variance, plotted below:

```{r}
#| label: var_genes

gene_var <- modelGeneVar(sce, assay.type = "logcounts")

gene_var %>% 
  # convert to tibble for ggplot
  as_tibble() %>% 
  # make the plot
  ggplot(aes(mean, total)) +
  geom_point() +
  geom_line(aes(y = tech), colour = "dodgerblue", size = 1) +
  labs(x = "Mean of log-expression", y = "Variance of log-expression")
```
- Use `getTopHVGs` to get the most variable genes, no set rule on number of genes to picked start with 10 % and adjust if needed.

```{r}
#| label: hvgs

hvgs <- getTopHVGs(gene_var, prop=0.1)
```

- There are `r length(hvgs)` highly variable genes that have been identified
- Expression of top 20 highly variable genes:

```{r}
#| label: plot-hvgs

plotExpression(sce, features = hvgs[1:20], point_alpha = 0.05, jitter = "jitter")
```

## PCA

- Principal Component Analysis (PCA) is the direction where the data is most spread out i.e. has the **highest variance**, can be both biological but also technical variation too.
    - The 1st principle component explains the most variance the data, followed by PC2, PC3 etc.
    - Looking for the minimum number of PC's to explain \~80 % of the variation in the library, can also use a "elbow" method on a scree plot.
    - Adds PC results into a Dimension Reductions (reduced Dims) slot, assumes that 50 PCs will capture most variance so defaults to this ncomponents.
    - This PCA will be based on **only the highly variable genes** determined above. ++ Use `reducedDim(sce, "PCA")[1:10, 1:5]` to view the first few rows/columns.

```{r}
#| label: run-PCA

sce <- runPCA(sce, subset_row = hvgs)

# extract variance explained
pca_pct_variance <- data.frame(variance = attr(reducedDim(sce, "PCA"), "percentVar"))
pca_pct_variance$PC <- 1:nrow(pca_pct_variance)
```

- Select number of principal components by finding the "elbow" of the scree plot, this can also be calculated from the `findElbowPoint` function (see `line 828` below)

```{r}
#| label: scree-plot

pca_pct_variance %>% 
  ggplot(aes(PC, variance)) +
  geom_col() +
  labs(y = "Variance explained (%)")
```

- Basic PCA plots, `ncomponents` argument allows you to state the number of PCs you wish to compare.

```{r}
#| label: PCA-basic

plotReducedDim(sce, dimred = "PCA", ncomponents = 2, colour_by = "Sample", shape_by = "treatment")
```

- Customise your PCA plot with `ggcells` to look at experimental factors impact on the PC plot, e.g. Genotype, chip, sample processing day, genes detected etc.

```{r}
#| label: PCA-custom

# more custom visualisations with ggcells (e.g. add facets)
ggcells(sce, aes(x = PCA.1, y = PCA.2, colour = Sample)) +
  geom_point(size = 0.5) +
  facet_wrap(~ treatment) +
  labs(x = "PC1", y = "PC2", colour = "Sample", title = "Treatment")

ggcells(sce, aes(x = PCA.1, y = PCA.2, colour = detected)) +
  geom_point(size = 0.5) +
  facet_wrap(~ treatment) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "PC1", y = "PC2", colour = "detected genes", title = "Treatment")
```

## Interpreting Principal Components

- Determine if there are any relationships between your experimental variables and PC scores.
    - Change a list of variables to match **your** experimental design from `colnames(colData(sce))`
    - In this example sample/Fixative seems to have a large influence on PC1-3.

```{r}
#| label: explan-pcs

explan_pcs <- getExplanatoryPCs(sce,
    variables = c(
        "sum",
        "detected",
        "Sample",
        "treatment",
        "No_of_Genes",
        "Exon_Reads",
        "subsets_Mito_percent"
    )
)
plotExplanatoryPCs(explan_pcs/100)

rm(explan_pcs)
```

- Calculate the percentage of variance in each genes expression "explained" by a technical or biological variable.

```{r}
#| label: vars-explained

vars <- getVarianceExplained(sce,  variables = c(
        "sum",
        "detected",
        "Sample",
        "treatment",
        "No_of_Genes",
        "Exon_Reads",
        "subsets_Mito_percent"
    ))

plotExplanatoryVariables(vars)

rm(vars)
```

- Identify the inflection point i.e. elbow on scree plot using the "explained" variances:

```{r}
#| label: scree-plot2

chosen_elbow <- findElbowPoint(pca_pct_variance$variance)

pca_pct_variance %>% 
  ggplot(aes(PC, variance)) +
  geom_point() +
  geom_vline(xintercept = chosen_elbow)+
  geom_text(x = chosen_elbow, label = paste(chosen_elbow, "PCs before elbow"), y = 5, colour = "blue", angle = 90, vjust = 1.5)

rm(chosen_elbow)
```

## Denoise PCA

- Using the gene variance calculated on line `710` run a "denoise" on the PCA to remove all PCs that are believed to capture more technical noise than real variation. ++ Output will be the number of PCs thought to be sufficient to capture most of the variation, type `?denoisePCA` in the console for full description. ++ Should be a similar output value to the chosen PC number above.

```{r}
#| label: denoise

sce <- denoisePCA(sce,  technical = gene_var)

ncol(reducedDim(sce, "PCA"))
```

## t-SNE

- [t-Distributed Stochastic Neighbor Embedding (t-SNE)](https://www.youtube.com/watch?v=NEaUSP4YerM)
    - Data is scaled and exaggerated in t-SNE and UMAP, and therefore not suitable for downstream analysis, **only for visualisation**!
    - Seed setting ensures cluster reproducibility if re-run, this is a random number
    - Within-cluster distances are preserved but distance between cluster positions are often not meaningful
      - [Guide to t-SNE intepretation](https://distill.pub/2016/misread-tsne/)
    - Can observe read types or expression of cell-type specific genes overlaid on these t-SNE clusters, remember the scaling means DEGs **cannot** be inferred from dimension reducing methods.

```{r}
#| label: t-SNE

set.seed(123) 

sce <- scater::runTSNE(sce,
                       name = "TSNE_perplex50",
                       perplexity = 50,
                       dimred = "PCA")
# To Visualise 

ggcells(sce, aes(x = TSNE_perplex50.1, y = TSNE_perplex50.2, colour = Sample,
                 shape = treatment)) + 
      geom_point() +
      theme_minimal() +
      theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(),  
        axis.ticks.y=element_blank()) +
      coord_fixed()

# Investigate specific attributes or genes
ggcells(sce, aes(x = TSNE_perplex50.1, y = TSNE_perplex50.2,
                 colour = No_of_Genes))+
  facet_wrap(~ Sample) +
  geom_point()+
  scale_color_viridis_b()+
   theme_minimal() +
      theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(),  
        axis.ticks.y=element_blank()) +
      coord_fixed()

ggcells(sce, aes(x = TSNE_perplex50.1, y = TSNE_perplex50.2,
                 colour = treatment))+
  facet_wrap(~ Sample) +
  geom_point()+
  scale_color_viridis_d()+
   theme_minimal() +
      theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(),  
        axis.ticks.y=element_blank()) +
      coord_fixed()

```

## UMAP

- [Uniform Manifold Approximation and projection (UMAP)](https://umap-learn.readthedocs.io/en/latest/)
    - Similar dimension reduction method, but faster and less intensive as it uses the PCs
    - Preserves better global structure i.e. between cluster comparisons more meaningful (slightly disputed, as can be over-interpreted).
    - May need to adjust the number of neighbours to get appropriate clustering, re-run as needed.

```{r}
#| label: UMAP

set.seed(123) # set seed for reproducibility
sce <- runUMAP(sce,
               name = "UMAP_neighbors50",
               dimred = "PCA",
               n_neighbors = 50)

# To Visualise 
ggcells(sce, aes(x = UMAP_neighbors50.1, y= UMAP_neighbors50.2, colour = Sample,
                 shape = treatment))+
  geom_point()+
   theme_minimal() +
      theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(),  
        axis.ticks.y=element_blank()) +
      coord_fixed()

ggcells(sce, aes(x = UMAP_neighbors50.1, y= UMAP_neighbors50.2, colour = No_of_Genes))+
  facet_wrap(~ Sample) +
  geom_point()+
  scale_color_viridis_b()+
   theme_minimal() +
      theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(),  
        axis.ticks.y=element_blank()) +
      coord_fixed()

ggcells(sce, aes(x = UMAP_neighbors50.1, y= UMAP_neighbors50.2, colour = treatment))+
  facet_wrap(~ Sample) +
  geom_point()+
  scale_color_viridis_d()+
   theme_minimal() +
      theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(),  
        axis.ticks.y=element_blank()) +
      coord_fixed()


```

- The choice between t-SNE and UMAP plots is largely personal, either way the plots should display the **underlying biology**.

```{r}
#| label: RDS-DimRed

saveRDS(sce, "results/1st_Syk_chip/DimRed.rds")
saveRDS(gene_var, "results/1st_Syk_chip/GeneVar.rds")
```

# Clustering

- Unsupervised clustering will help identify groups of cells based on the transcriptomes.
- Details about the [methods](https://www.singlecellcourse.org/biological-analysis.html#clustering-introduction).
- Unlike Hierarchical or k-means clustering, graph-based clustering was **developed for scSeq data**, as it's fast and memory efficient even on large datasets and doesn't rely on a pre-specified cluster number.
- It uses a nearest-neighbour graph with cells as nodes to detect communities (i.e. highly interconnected nodes). Considered linked by k-NN and shared-NN.
  -   Assess accuracy of the communities/clusters using the modularity metric, overall a value close to 1 is ideal.
  -   When building the network you will need to consider the number of appropriate nearest neighbours.

## Graph-based clustering

- Walktrap method (not shown)
  -   Short random walks through the network which tend to be "trapped" in highly connected regions.
  -   Repeated walks produce a dendrogram of distances which is then clustered hierarchically.
- Louvain method and Leiden method (see below).

### Build an SNN graph (universal)

-   Clears the environment and load in data from 1 chip, 2 chips or 2+ chips as one sce object (default is 2+ chips).
-   If you would prefer to run UMAP plots change `runTSNE` to be `runUMAP`.

```{r}
#| label: clustering_load

set.seed(123)
# Data from 1 chip
sce$Sample <- factor(sce$Sample)
sce <- runTSNE(sce, dimred = "PCA")
snn.gr <- buildSNNGraph(sce, use.dimred = "PCA")

# Data from 2 chips, load uncorrected files for later comparisons
    # sce <- readRDS("results/corr_sce_2chip.rds")
    # sce$Sample <- factor(sce$Sample)
    # sce <- runTSNE(sce, dimred = "corrected")
    # snn.gr <- buildSNNGraph(sce, use.dimred = "corrected")
    
# Data from 2+ chips
 # sce <- readRDS("results/corr_sce_all.rds")
 # sce$Sample <- factor(sce$Sample)
 # sce <- runTSNE(sce, dimred = "corrected")
 # snn.gr <- buildSNNGraph(sce, use.dimred = "corrected")
```

### Louvain Clustering

- Nodes are assigned their own community, works bottom-up (agglomerative method) to re-assign nodes to the community for which they increase the modularity the most (i.e. improves clustering most).
- Repeated iteratively until modularity/clustering cannot be further improved.
- Run on the SNN graph, outputs are the cluster number and cells belonging to each cluster and a t-SNE visual summary.

```{r}
#| label: Louvain

# Perform the clustering on the SNN graph
ig.louvain <- igraph::cluster_louvain(snn.gr)

# Extract clusters and store membership in the sce
cl <- ig.louvain$membership
head(cl)
cl <- factor(cl)
sce$louvain <- cl

# number and size of clusters
table(sce$louvain)

# t-SNE plot
plotTSNE(sce, colour_by="louvain") 

rm(ig.louvain, cl)
```

- Assess the quality by looking at per-cluster modularity on a heatmap, a high diagonal score and low values elsewhere suggest clear separation.
  - Clusterwise modularity is computed with `clusterModularity` which is proportional to the cluster size so convert to a ratio of observed vs expected for each pair.

```{r}
#| label: QC_Louvain

# Compute cluster-wise modularities
mod.out <- bluster::pairwiseModularity(snn.gr,
                                       #wt.clusters,
                                       sce$louvain,
                                       get.weights=TRUE)

# Ratio of the observed to expected weights
ratio <- mod.out$observed/mod.out$expected
lratio <- log10(ratio + 1) # on log scale to improve colour range

# Plot heatmap

pheatmap(lratio, cluster_rows=FALSE, cluster_cols=FALSE, 
    col=rev(viridis::magma(100)), main="Louvain Clustering Modularity")

rm(mod.out, ratio, lratio)
```

### Leiden Clustering

- [Methods paper](https://www.nature.com/articles/s41598-019-41695-z):
- Improves on Louvain as it adds a refinement step which checks at each iteration that clusters are connected and well separated, to prevent it from grouping disconnected sub-clusters together.
- For the most part igraph `cluster_leiden` function will suffice.

```{r r_Leiden}
# Leiden clustering and store IDs
partition <- igraph::cluster_leiden(snn.gr)

 #Extract clusters and store membership in the sce
cl <- partition$membership
head(cl)
cl <- factor(cl)
sce$leiden <- cl

# number and size of clusters
# table(sce$leiden)

# t-SNE plot
plotTSNE(sce, colour_by="leiden", text_by="leiden") 

rm(partition, cl)
```

- To get the [full functionality](https://github.com/vtraag/leidenalg) you will need to use `reticulate` package and create a virtual conda environment before running this analysis.

#Reticulate is a nightmare so I'm skipping this

```{r}
#| label: conda_Leiden
#| eval: false

#BiocManager::install("reticulate")
library(reticulate)
#reticulate::install_miniconda() 

# Then create a python (v3.8) environment and install the required packages (using the following code, one line at a time as you have to type "y" to proceed) in the Anaconda prompt that will be in your recently added section of the start menu. 
# To run this on a laptop you will need to install Visual Studio and NSight compute modules so it can run via the graphics processor.


conda create -n NA
conda activate NA
conda config --env --add channels conda-forge
conda install -c conda-forge numpy
conda install -c conda-forge pandas
conda install -c conda-forge r-reticulate
conda install -c conda-forge umap-learn
conda install -c conda-forge python-igraph
conda install -c conda-forge/label/cf202003 leidenalg
conda deactivate

# Restart your R session (ctrl+shift+F10)
# Run Leiden clustering, output will be the number and size of clusters.
library(reticulate)
reticulate::use_condaenv("C:/Users/c1650826/Anaconda3/envs/NA/")
#reticulate::conda_install("r-reticulate", "leidenalg")
library(leiden)# n to install dependencies, should be installed.
# Lists all installed packages and python configuration
# py_list_packages()
# py_config
# Check required python modules are installed (returns TRUE)


py_module_available("leidenalg")

adjacency_matrix <- igraph::as_adjacency_matrix(snn.gr)

# Leiden clustering and store IDs
partition <- leiden(adjacency_matrix)
sce$leiden <- factor(partition)

# number and size of clusters
table(sce$leiden)
```

### Comparing Clustering

- To compare the Louvain and Leiden clustering methods in your dataset, they should be similar.

```{r}
#| label: QC_clusters

# Create table and add labels
tmpTab <- table(sce$louvain, sce$leiden)
rownames(tmpTab) = paste("louvain", rownames(tmpTab), sep = "_")
colnames(tmpTab) = paste("leiden", colnames(tmpTab) , sep = "_")

# Create heatmap
pheatmap(tmpTab, cluster_rows=FALSE, cluster_cols=FALSE, 
    col=rev(viridis::magma(100)), main="Louvain vs Leiden Clustering")

rm(tmpTab)
```

```{r RDS_clustering}
saveRDS(sce, "results/1st_Syk_chip/Clustered.rds")
rm(list = ls())
```

I think the sce clustering is not great, and I much prefer seurat, so I'm redoing the clustering with seurat.
#Convert to seurat
```{r}

seurat <- as.Seurat(sce, counts = "counts", data = "logcounts")
```

#I'm using SCTtransform instead of NormalizeData(), ScaleData(), and FindVariableFeatures().

-sctransform method models the UMI counts using a regularized negative binomial model to remove the variation due to sequencing depth (total nUMIs per cell), while adjusting the variance based on pooling information across genes with similar abundances (similar to some bulk RNA-seq methods).

-SCTtransform also allows to regress out unwanted variation

-Sctransform automatically regresses out sequencing depth (nUMIs); however, there are other sources of uninteresting variation in the data that is often specific to the dataset. For example, for some datasets, cell cycle phase may be a source of significant variation, while for other datasets it isnâ€™t. Before you would regress out variation due to cell cycle phase, you would need to check whether cell cycle phase is a major source of variation in the data.

- Also sctransform returns 3,000 variable features by default

#Cell cycle scoring
It is recommended to check the cell cycle phase before performing the sctransform method. 

```{r}
# Normalize the counts - This is just to perform the cell scoring - we will then normalize using SCTransform

seurat <- NormalizeData(seurat)

```

We want to see if cell cycle differences lead to unwanted variation in our data that can be regressed out to clean the data

```{r}
# Cell cycle scoring 
# Read in cell cycle genes - these exist as part of seurat 
cell_cycle <- cc.genes.updated.2019
#Convert to mouse common gene names using gprofiler
library(gprofiler2)
#Extract and convert the S genes
mmus_s <-  gorth(cc.genes.updated.2019$s.genes, source_organism = "hsapiens", target_organism = "mmusculus")$ortholog_name
#Extract and convert the G2/M genes 
mmus_g2m <- gorth(cc.genes.updated.2019$g2m.genes, source_organism = "hsapiens", target_organism = "mmusculus")$ortholog_name
```
-The CellCycleScoring() function stores S and G2/M scores in seurat@metadata in the S.Score and G2M.Score columns, along with the predicted classification of each cell in either G2M, S or G1 phase in the Phase column.

```{r}
# Perform cell cycle scoring
seurat <- CellCycleScoring(seurat, s.features = mmus_s, g2m.features = mmus_g2m)

# Identify the most variable genes
seurat_phase <- FindVariableFeatures(seurat, 
                     selection.method = "vst",
                     nfeatures = 2000, 
                     verbose = FALSE)
		     
# Scale the counts
seurat_phase <- ScaleData(seurat_phase)


#Determine if the cells group by cell cycle, using PCA and color by cell cycle phase
# Perform PCA
seurat_phase <- RunPCA(seurat_phase,
  pc.genes = c(mmus_s, mmus_g2m),
  do.print = FALSE)


# Plot the PCA colored by cell cycle phase
DimPlot(seurat_phase,
        reduction = "pca",
        group.by= "Phase",
        split.by = "Phase")
```
No differences due to cell cycle phase we can go ahead and perform SCTransform


```{r}
#SCTransform will look for RNA in the assay slot , so we need to change the name of our assay to RNA
seurat <- RenameAssays(object = seurat, originalexp = 'RNA')
DefaultAssay(seurat)
# Split seurat object by condition(treatment) to perform SCT on all samples
split_seurat <- SplitObject(seurat, split.by = "treatment")
ctrl <- split_seurat[["Control"]]
stim <- split_seurat[["Treated"]]
```

#Perform SCTransform and PCA
#For control
```{r}
#For control dataset - vst.flavor=v2 is the most recent and best SCTransform
ctrl <- SCTransform(ctrl, vst.flavor = "v2", verbose = FALSE) 
#Ensure default is SCT
DefaultAssay(ctrl)
#Run PCA 
ctrl <- RunPCA(ctrl, npcs = 50, verbose = FALSE)
# visualize PCA results - top 5 most variable genes for first 10 PCs
print(ctrl[["pca"]], dims = 1:6, nfeatures = 5)
#Make heatmaps of first 6 PCs - the  genes and cells are ordered by PC scores - this allows to explore expression of most extreme genes per PC
DimHeatmap(ctrl, dims = 1:6, balanced = TRUE)
#Find how many PCs explain the data
print(ElbowPlot(ctrl))
```
-calculate where the principal components start to elbow by taking the larger value of:

The point where the principal components only contribute 5% of standard deviation and the principal components cumulatively contribute 90% of the standard deviation.
The point where the percent change in variation between the consecutive PCs is less than 0.1%.

```{r}
#For the 1st metric
# Determine percent of variation associated with each PC
pct <- ctrl@reductions$pca@stdev / sum(ctrl@reductions$pca@stdev) * 100

# Calculate cumulative percents for each PC
cumu <- cumsum(pct)

# Determine which PC exhibits cumulative percent greater than 90% and % variation associated with the PC as less than 5
co1 <- which(cumu > 90 & pct < 5)[1]

print(co1)
```

```{r}
#For the 2nd metric
# Determine the difference between variation of PC and subsequent PC
co2 <- max(which((pct[1:length(pct)-1] - pct[2:length(pct)]) > 0.1)) + 1
# last point where change of % of variation is more than 0.1%.

print(co2)
```
I'm using 45 PCs for clustering and resolutions for control

#Perform SCTransform and PCA
#For treated
```{r}
#For treated(stim) dataset - vst.flavor=v2 is the most recent and best SCTransform
stim<- SCTransform(stim, vst.flavor = "v2", verbose = FALSE) 
#Ensure default is SCT
DefaultAssay(stim)
#Run PCA 
stim <- RunPCA(stim, npcs = 50, verbose = FALSE)
# visualize PCA results - top 5 most variable genes for first 10 PCs
print(stim[["pca"]], dims = 1:6, nfeatures = 5)
#Make heatmaps of first 6 PCs - the  genes and cells are ordered by PC scores - this allows to explore expression of most extreme genes per PC
DimHeatmap(stim, dims = 1:6, balanced = TRUE)
#Find how many PCs explain the data
print(ElbowPlot(stim))
```
-calculate where the principal components start to elbow by taking the larger value of:

The point where the principal components only contribute 5% of standard deviation and the principal components cumulatively contribute 90% of the standard deviation.
The point where the percent change in variation between the consecutive PCs is less than 0.1%.

```{r}
#For the 1st metric
# Determine percent of variation associated with each PC
pct <- stim@reductions$pca@stdev / sum(stim@reductions$pca@stdev) * 100

# Calculate cumulative percents for each PC
cumu <- cumsum(pct)

# Determine which PC exhibits cumulative percent greater than 90% and % variation associated with the PC as less than 5
co1 <- which(cumu > 90 & pct < 5)[1]

print(co1)
```
```{r}
#For the 2nd metric
# Determine the difference between variation of PC and subsequent PC
co2 <- max(which((pct[1:length(pct)-1] - pct[2:length(pct)]) > 0.1)) + 1
# last point where change of % of variation is more than 0.1%.

print(co2)
```
I'm using 45 PCs for clustering and resolutions for control and stim
#For control - clustering
```{r}
ctrl <- RunUMAP(ctrl, reduction = "pca", dims = 1:45, verbose = FALSE) %>%
FindNeighbors(reduction = "pca", dims = 1:45, verbose = FALSE) %>%
    FindClusters(resolution =c(0.3,0.5,0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5), verbose = FALSE)
```

#Plot different resolutions for ctrl
```{r}
p1 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.3" ) + ggtitle("SCT resolution 0.3")
p2 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.3" ) + ggtitle("SCT resolution 0.5")
p3 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.7" ) + ggtitle("SCT resolution 0.7")
p4 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.8" ) + ggtitle("SCT resolution 0.8")
p5 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.9" ) + ggtitle("SCT resolution 0.9")
p6 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1" ) + ggtitle("SCT resolution 1")
p7 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.1" ) + ggtitle("SCT resolution 1.1")
p8 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.2" ) + ggtitle("SCT resolution 1.2")
p9 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.3" ) + ggtitle("SCT resolution 1.3")
p10 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.4" ) + ggtitle("SCT resolution 1.4")
p11 <- DimPlot(ctrl, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.5" ) + ggtitle("SCT resolution 1.5")
print(p1)
print(p2)
print(p3)
print(p4)
print(p5)
print(p6)
print(p7)
print(p8)
print(p9)
print(p10)
print(p11)
```
#For treated - clustering

```{r}
stim <- RunUMAP(stim, reduction = "pca", dims = 1:45, verbose = FALSE) %>%
FindNeighbors(reduction = "pca", dims = 1:45, verbose = FALSE) %>%
    FindClusters(resolution =c(0.3,0.5,0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5), verbose = FALSE)

```

#Plot different resolutions for treated
```{r}
p1 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.3" ) + ggtitle("SCT resolution 0.3")
p2 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.3" ) + ggtitle("SCT resolution 0.5")
p3 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.7" ) + ggtitle("SCT resolution 0.7")
p4 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.8" ) + ggtitle("SCT resolution 0.8")
p5 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.0.9" ) + ggtitle("SCT resolution 0.9")
p6 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1" ) + ggtitle("SCT resolution 1")
p7 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.1" ) + ggtitle("SCT resolution 1.1")
p8 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.2" ) + ggtitle("SCT resolution 1.2")
p9 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.3" ) + ggtitle("SCT resolution 1.3")
p10 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.4" ) + ggtitle("SCT resolution 1.4")
p11 <- DimPlot(stim, reduction="umap", label = T, repel = T, group.by= "SCT_snn_res.1.5" ) + ggtitle("SCT resolution 1.5")
print(p1)
print(p2)
print(p3)
print(p4)
print(p5)
print(p6)
print(p7)
print(p8)
print(p9)
print(p10)
print(p11)
```

```{r}
saveRDS(ctrl, "results/1st_Syk_chip/ctrl_sctransform_Seurat.rds")
saveRDS(stim, "results/1st_Syk_chip/treated_sctransform_Seurat.rds")
```

I think it's best to use chooseR to find the optimal clustering resolution - see chooseR markdown

#chooseR optimal res = 1
#Reupload ctrl and stim
```{r}
ctrl <- readRDS("results/1st_Syk_chip/ctrl_sctransform_Seurat.rds")
stim <- readRDS("results/1st_Syk_chip/treated_sctransform_Seurat.rds")
```

#Set res 1 as idents and seurat clusters

```{r}
# Setting identity of clusters for ctrl
Idents(ctrl) <- "SCT_snn_res.1"
ctrl$seurat_clusters <- Idents(ctrl)
# Setting identity of clusters for stim
Idents(stim) <- "SCT_snn_res.1"
stim$seurat_clusters <- Idents(stim)
```


```{r}
#Now we integrate across conditions
Syk_list <- list(ctrl = ctrl, stim = stim)
features <- SelectIntegrationFeatures(object.list = Syk_list, nfeatures = 3000)
Syk_list <- PrepSCTIntegration(object.list = Syk_list, anchor.features = features)
```


#Integrate the data with CCA

```{r}
anchors <- FindIntegrationAnchors(object.list = Syk_list, normalization.method = "SCT", anchor.features = features)
integrated_seurat <- IntegrateData(anchorset = anchors, normalization.method = "SCT")
```
#Perform the normal clustering steps for the combined data same as above

```{r}
 integrated_seurat <- RunPCA(integrated_seurat, npcs = 50, verbose = FALSE)
 integrated_seurat<- RunUMAP(integrated_seurat, reduction = "pca", dims = 1:45, verbose = FALSE)
integrated_seurat <- FindNeighbors(integrated_seurat, reduction = "pca", dims = 1:45)
integrated_seurat <- FindClusters(integrated_seurat, resolution = 1)
```

```{r}
# Setting identity of clusters for integrated_seurat
Idents(integrated_seurat) <- "integrated_snn_res.1"
integrated_seurat$seurat_clusters <- Idents(integrated_seurat)
```

#Let's plot this
```{r}
DimPlot(integrated_seurat, reduction = "umap", group.by = "treatment")
DimPlot(integrated_seurat, reduction = "umap", split.by = "treatment", label=TRUE)

```
Looking good - I'm going ahead and performing cell annotation

```{r}
#calculate the number of cells in each cluster that came for each condition in integrated_Seurat
 
 count_table <- table(integrated_seurat@meta.data$seurat_clusters, integrated_seurat@meta.data$treatment)
 print(count_table)
 
```

# Identifying Cluster Marker genes

Let's start with sc-type for cell annotation
#Sc-type
```{r}
#Load libraries
lapply(c("dplyr","Seurat","HGNChelper","openxlsx"), library, character.only = T)
# load gene set preparation function
source("https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/R/gene_sets_prepare.R")
# load cell type annotation function
source("https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/R/sctype_score_.R")

```

```{r}
# DB file
db_ = "https://raw.githubusercontent.com/IanevskiAleksandr/sc-type/master/ScTypeDB_full.xlsx";
tissue = "Brain" # e.g. Immune system,Pancreas,Liver,Eye,Kidney,Brain,Lung,Adrenal,Heart,Intestine,Muscle,Placenta,Spleen,Stomach,Thymus 

# prepare gene sets
gs_list = gene_sets_prepare(db_, tissue)


```


```{r}


# get cell-type by cell matrix
es.max = sctype_score(scRNAseqData = integrated_seurat[["integrated"]]@scale.data, scaled = TRUE, 
                      gs = gs_list$gs_positive, gs2 = gs_list$gs_negative) 

 #merge by cluster
cL_results = do.call("rbind", lapply(unique(integrated_seurat@meta.data$seurat_clusters), function(cl){
    es.max.cl = sort(rowSums(es.max[ ,rownames(integrated_seurat@meta.data[integrated_seurat@meta.data$seurat_clusters==cl, ])]), decreasing = !0)
    head(data.frame(cluster = cl, type = names(es.max.cl), scores = es.max.cl, ncells = sum(integrated_seurat@meta.data$seurat_clusters==cl)), 10)
}))
sctype_scores = cL_results %>% group_by(cluster) %>% top_n(n = 1, wt = scores)  

# set low-confident (low ScType score) clusters to "unknown"
sctype_scores$type[as.numeric(as.character(sctype_scores$scores)) < sctype_scores$ncells/4] = "Unknown"
print(sctype_scores[,1:3])

```

Cluster 3 can just as likely be Immune system cells.

I'm going to go ahead and use SingleR and start with the Tabula muris senis reference
#SingleR - Tabula muris Senis
#Anndata is not working properly so I'm using zellconverter to upload the adata and convert it to sce
```{r}
library(zellkonverter)
ref_myeloid <- readH5AD ("tabula_muris_senis_facs_Brain_Myeloid.h5ad")
ref_non_myeloid <- readH5AD ("tabula_muris_senis_facs_Brain_Non-Myeloid.h5ad")
```
The references don't have the data in the right place so I'm converting to Seurat and then back to SCE

```{r}
#Convert to Seurat 
ref_myeloid_seurat <- CreateSeuratObject(counts = ref_myeloid@assays@data$X)
ref_non_myeloid_seurat <- CreateSeuratObject(counts = ref_non_myeloid@assays@data$X)

```

#Manually add metadata

```{r}
metadata_ref_myeloid <- as.data.frame.matrix(colData(ref_myeloid))
metadata_ref_non_myeloid <- as.data.frame.matrix(colData(ref_non_myeloid))
ref_myeloid_seurat <- AddMetaData(ref_myeloid_seurat, metadata_ref_myeloid, col.name = NULL)
ref_non_myeloid_seurat <- AddMetaData(ref_non_myeloid_seurat, metadata_ref_non_myeloid, col.name = NULL)
```


```{r}
unique(ref_myeloid_seurat$cell_ontology_class)
unique(ref_non_myeloid_seurat$cell_ontology_class)

```
#Convert corrected references back to sce and lognormalize them

```{r}
ref_myeloid <- as.SingleCellExperiment(ref_myeloid_seurat)
ref_non_myeloid <- as.SingleCellExperiment(ref_non_myeloid_seurat)
ref_myeloid <- logNormCounts(ref_myeloid)
ref_non_myeloid <- logNormCounts(ref_non_myeloid)
```

#Run SingleR and save references in case needed in future

```{r}
saveRDS(ref_myeloid, "results/1st_Syk_chip/ref_myeloid_sce.rds")
saveRDS(ref_non_myeloid, "results/1st_Syk_chip/ref_non_myeloid_sce.rds")

results_tabula_muris_senis <- SingleR(test = as.SingleCellExperiment(integrated_seurat), ref = list(ref_myeloid, ref_non_myeloid), labels =list(ref_myeloid$cell_ontology_class, ref_non_myeloid$cell_ontology_class))

```


```{r}
#Add tabula muris senis singleR label

integrated_seurat$singlr_tabula_m_senis <- results_tabula_muris_senis$labels[match(rownames(integrated_seurat@meta.data), rownames(results_tabula_muris_senis))]

p1 <- DimPlot(integrated_seurat, reduction = "umap", group.by = "seurat_clusters", label = TRUE) + ggtitle ("Seurat clusters")
p2 <- DimPlot(integrated_seurat, reduction = 'umap', group.by = 'singlr_tabula_m_senis') + ggtitle("singlR tabula muris senis labels")

print(p1|p2)

```
This looks like it failed spectacularly, let's do some annotation QC

Maybe because this was log Normalized and our data was SCTransformed this isn't working well - SCTransform doesn't respect the original ranking

I'm redoing this with the raw Data - change default assay to RNA

```{r}
DefaultAssay(object = integrated_seurat) <- "RNA"
GetAssay(integrated_seurat)

```
Redo SingleR

```{r}

results_tabula_muris_senis <- SingleR(test = as.SingleCellExperiment(integrated_seurat), ref = list(ref_myeloid, ref_non_myeloid), labels =list(ref_myeloid$cell_ontology_class, ref_non_myeloid$cell_ontology_class))
```

Re-add the singleR labels
```{r}
#Add tabula muris senis singleR label

integrated_seurat$singlr_tabula_m_senis <- results_tabula_muris_senis$labels[match(rownames(integrated_seurat@meta.data), rownames(results_tabula_muris_senis))]

p1 <- DimPlot(integrated_seurat, reduction = "umap", group.by = "seurat_clusters", label = TRUE) + ggtitle ("Seurat clusters")
p2 <- DimPlot(integrated_seurat, reduction = 'umap', group.by = 'singlr_tabula_m_senis') + ggtitle("singlR tabula muris senis labels")

print(p1|p2)

```

This looks much better and much more like what I would expect - I'm sure it was because of the SCTransform that it didn't work well before

Let's go ahead and do the Annotation QC

```{r}
#Annotation QC
#Check cell scores - The score for one label should be larger than for other labels
results_tabula_muris_senis$scores
#Plot heatmap - as you can see from the heatmap the scores within each label are not unambiguous apart from ARM cells and to a lesser extent MHC.high
plotScoreHeatmap(results_tabula_muris_senis)
```

```{r}
#Let's get the deltas

plotDeltaDistribution(results_tabula_muris_senis)

```

```{r}
tab_muris_senis <- table(Assigned=results_tabula_muris_senis$labels, Clusters=integrated_seurat$seurat_clusters)
tab_muris_senis
pheatmap(log10(tab_muris_senis+10), color = colorRampPalette(c('white','blue'))(10))

```
SingleR annotation QC shows confidence in microglia assignments. There is some level od contamination in cluster 3 with what it says are macrophages -I don't trust the macrophage assignment as much

I think we move now to try so use SingleR to check microglia populations and AUCell

I', using a reference created from this paper to try to ID microglia subtypes - [Sierksma et al., 2020] Novel Alzheimer risk genes determine the microglia response to amyloid-Î² but not to TAU pathology (https://www.embopress.org/doi/full/10.15252/emmm.201910606), using 
GSE142267

```{r}
ref_Sierksma <- readRDS("ref_Sierksma.rds")
```

```{R}
unique(ref_Sierksma$cell.state)
```
These are the microglia subtypes in the Sierksma reference

#Perform SingleR for ref_Sierksma

```{r}
results_Sierksma <- SingleR(test = as.SingleCellExperiment(integrated_seurat), ref = ref_Sierksma, labels = ref_Sierksma$cell.state)

```

Add the singleR labels for ref_Sierksma
```{r}
#Add Sierksma singleR label

integrated_seurat$singlr_sierksma <- results_Sierksma$labels[match(rownames(integrated_seurat@meta.data), rownames(results_Sierksma))]

p3 <- DimPlot(integrated_seurat, reduction = "umap", group.by = "singlr_sierksma") + ggtitle ("singleR Sierksma labels")

print(p1|p3)

```

Most microglia cells seem to be homeostatic - HM.1, there's a HMC high cluster - cluster 3 (could potentially be DAM).

#Let's do some annotation QC

```{r}
#Annotation QC
#Check cell scores - The score for one label should be larger than for other labels
results_Sierksma$scores
#Plot heatmap - as you can see from the heatmap the scores within each label should be a yellow block if not are not unambiguous 
plotScoreHeatmap(results_Sierksma)
```
It's more likely that these cells are HM.1, CPM, a small number of HM.2 and HMC.high.

```{r}
#Plot deltas - deltas identify poor quality assignments - low delta values means the assignment is uncertain because delta is the difference between the score for the assigned label and the median across all labels for each cell

plotDeltaDistribution(results_Sierksma)

```
```{r}
#Compare to unsupervised clustering
tab <- table(Assigned=results_Sierksma$labels, Clusters=integrated_seurat$seurat_clusters)
tab
pheatmap(log10(tab+10), color = colorRampPalette(c('white','blue'))(10))

```
I don't think this needs repeating with a new reference, I'm happy to move to AUCell and specific microglia markers.


AUCell allows you to identify cells with active-gene sets and you can use it to ID cell type (and a lot more).

For the ID markers I'm going to use for microglia the paper [Pettas et al., 2022], Profiling Microglia through Single-Cell RNA Sequencing over the Course of Development, Aging, and Disease (https://www.mdpi.com/2073-4409/11/15/2383) and PanglaoDB to get general markers of microglia ,as well as,

```{r}
library(AUCell)
AUCell_markers <- read.delim("PanglaoDB_markers_27_Mar_2020.tsv", sep = "\t")
AUCell_micro <- AUCell_markers[AUCell_markers$cell.type == "Microglia"  &  AUCell_markers$species != "Hs",]
```

For AUCell you want a decent number of markers - ideally between 100-500, with at least ~ 50 genes

```{r}
#Get list of AUCell_markers
genes_micro <- AUCell_micro$official.gene.symbol

genes_micro

```
Note - mouse gene IDs are usually the first letter as an uppercase and the others as lower case, so we need to change this in out gene list

```{r}
#Create function mouseID that corrects gene names
mouse_ID <- function(a){
  return(paste0(substr(a,1,1), tolower(substr(a,2,nchar(a)))))
  
}


genes_micro <- sapply(genes_micro, mouse_ID)
genes_micro
```
```{r}
#Get the counts from seurat object
counts = GetAssayData(object = integrated_seurat, slot = "counts")
```

```{r}
#Pass counts through the AUCell_buildRankings function
cell_rankings <- AUCell_buildRankings(counts)

```


```{r}
#Calculate the AUC for each cell

#For microglia

cells_AUC_micro <- AUCell_calcAUC(genes_micro, cell_rankings)

```

```{r}
#For microglia
cells_assignment_micro <- AUCell_exploreThresholds(cells_AUC_micro, plotHist = TRUE, assign=TRUE)
```
Because we only have a cell population - microglia this is not a bimodal distribution - AUCell can't find a population where microglia cells are not expressed so it can't accurately find a cut-off and it won't work well , we'll provide the cut-off of 0.05 because we know all these cells are microglia if you don't know don't do this. The automatically assigned cells are under cells_assignment_xxx$geneSet$assignment

```{r}
cells_assignment_micro$geneSet$assignment

```

We can either use those or manually choose a threshold with cells <- names(which(getAUC(cells_AUC_xxxx)["geneSet",]> xxx))



```{r}
#Create new column in harmony_int
microglia <- names(which(getAUC(cells_AUC_micro)["geneSet",]>0.05))

integrated_seurat$is.microglia <- ifelse(colnames(integrated_seurat) %in% microglia, "microglia", "non_microglia")

```

#Plot this
```{r}
pmicro <- DimPlot(object = integrated_seurat, group.by = "is.microglia", label = TRUE)
plot(p1|pmicro)
```
Let's try AUCell with the markers from the [Lambratch-Washington et al., 2023] paper (https://www.sciencedirect.com/science/article/pii/S2589958923000038), the [Frigerio et al.,2019] paper https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7340153/ and the [Boche et al., 2020] paper https://alz-journals.onlinelibrary.wiley.com/doi/full/10.1002/alz.12389 

Some of these have a very small no of marker genes I'm unsure if this will work

```{r}

ARM <- c("Cst7", "Clec7a", "Itgax", "Cd74", "H2-Ab1", "H2-Aa", "Ctsb", "Ctsd", "Spp1", "Gpnmb",  "Dkk2")

IRM <- c("Ifit2", "Ifit3", "Ifitm3", "Irf7", "Oasl2" )

  
Homeostatic <- c( "Tgfbr1" , "Smad3", "C1qa", "C1qb", "Cst3", "Csf1r", "Ctsd", "Ctss", "Cx3cr1", "Entpd1", "Fcrls", "Hexb", "Olfml3", "P2ry12", "Tmem119", "Tmsb4x", "Sparc", "Lgmm", "Tppp", "Bin1", "Rgs10", "Gpr34", "Sall1")
  
Primed_Microglia <- c( "Alas1", "Amigo1", "Ank", "Ap3m2", "Aplp2", "Apoe", "Atp1a1", "Atp6v1a", "Atp6v1b2", "Atp8a2", "Axl", "B2m", "Bin1", "C3", "C3ar1", "Ccr5", "Cd68", "Cd84", "Cd74", "Cd9", "Cep68", "Ckb", "Clec7a", "Csf1", "Csf1r", "Cst7", "Ctsb", "Cul1", "Cybb", "Cx3cr1", "Eid1", "Elmo1", "F11r", "Galc", "Gas7", "Gbp2", "Glul", "Gmpr2", "Gng2", "Grn", "Gpnmb", "Gpr34", "Gpr84", "Gprasp1", "Hspa9", "Igf1", "Il1b", "Itgax", "Lgals3", "Mertk", "Nuak1", "Olfml3", "P2ry12", "P2ry13", "Psmb8", "Ppm1l", "Prkab1", "Rab6b", "Reep5", "Rhob", "Scoc", "Serinc3", "Slc2a5", "Slc24a3", "Slco2b1", "Smad3", "Sparc", "Spp1", "Stambpl1", "Stat1", "Tap1", "Tgfbr1", "Tjp1", "Tlr2", "Tmem119", "Tpi1", "Trim2", "Trim26", "Txn1", "Usp2")

Neurodegenerative_Microglia <- c("Adgrg1", "Apoe", "Axl", "Bhlhe40", "Bin1", "Ccr5", "Cd33", "Clec7a", "Csf1", "Csf1r", "Cst7", "Ctsb", "Ctsd", "Ctsl", "Cybb", "Cx3cr1", "Egr1", "Fabp5", "Fth1", "Glul", "Gnas", "Gpnmb", "Gpr34", "Grn", "Il1b", "Itgax", "Jun", "Lgals3", "Lilrb4a", "Lpl", "Lyz2", "Mafb", "Mef2a", "Mertk", "Msr1", "Nos2", "P2ry12", "Sall1", "Serinc3", "Siglech", "Smad3", "Spi1", "Spp1", "Tgfb1", "Tgfbr1", "Tfec", "Tmem119", "Trem2", "Tyrobp", "Vegfa")

DAM1 <- c("Apoe", "B2m", "Ctsb", "Ctsd", "Cx3cr1", "Fth1", "Lyz2", "P2ry12", "Tmem119", "Tyrobp")

DAM2 <- c("Axl", "Cd9", "Clec7a", "Csf1", "Cst7", "Ctsl", "Itgax", "Lilrb4a", "Lpl", "Timp2", "Trem2")

```


```{r}

#Calculate the AUC for each cell

#For ARM

cells_AUC_ARM <- AUCell_calcAUC(ARM, cell_rankings)

#For IRM

cells_AUC_IRM <- AUCell_calcAUC(IRM, cell_rankings)

#For Homeostatic

cells_homeostatic <- AUCell_calcAUC(Homeostatic, cell_rankings)

# For Primed_Microglia

cells_primed <- AUCell_calcAUC(Primed_Microglia, cell_rankings)

#For Neurodegenerative_Microglia

cells_Ndg_micro <- AUCell_calcAUC(Neurodegenerative_Microglia, cell_rankings)

#For DAM1

cells_DAM1 <- AUCell_calcAUC(DAM1, cell_rankings)

#For DAM2 

cells_DAM2 <- AUCell_calcAUC(DAM2, cell_rankings)


```

```{r}

#For ARM
cells_assignment_ARM <- AUCell_exploreThresholds(cells_AUC_ARM, plotHist = TRUE, assign=TRUE)
#For IRM
cells_assignment_IRM <- AUCell_exploreThresholds(cells_AUC_IRM, plotHist = TRUE, assign=TRUE)

```
I think the cut-off for ARM should be 0.3
and for IRM there is nothing there


```{r}

#For Homeostatic

cells_assignment_homestatic <- AUCell_exploreThresholds(cells_homeostatic, plotHist = TRUE, assign=TRUE)

# For Primed_Microglia

cells_assignment_primed <- AUCell_exploreThresholds(cells_primed, plotHist = TRUE, assign=TRUE)

#For Neurodegenerative_Microglia

cells_assignment_NG <- AUCell_exploreThresholds(cells_Ndg_micro, plotHist = TRUE, assign=TRUE)


```
This won't work there is no bimodal distribution so I can't define cell population cut-off

```{r}
#For DAM1

cells_assignment_DAM1 <- AUCell_exploreThresholds(cells_DAM1, plotHist = TRUE, assign=TRUE)

#For DAM2 

cells_assignment_DAM2 <- AUCell_exploreThresholds(cells_DAM2, plotHist = TRUE, assign=TRUE)


```

I'm not even going to plot this AUCell didn't work as I would have hoped so I'm going to have to check microglia subtypes manually.


I'm going to have to calculate markers for each cluster and then I'm just going to manually find the ID of each cluster

Let's do find markers for each genotype first:

- FindConservedMarkers needs to specify the starting cluster (which you want to identify). Let's start with cluster "0"
```{r}
cons_markers_cluster0 <- FindConservedMarkers(integrated_seurat,
                     ident.1 = 0,
                     grouping.var = 'treatment')

cons_markers_cluster1 <- FindConservedMarkers(integrated_seurat,
                     ident.1 = 1,
                     grouping.var = 'treatment')

cons_markers_cluster2 <- FindConservedMarkers(integrated_seurat,
                     ident.1 = 2,
                     grouping.var = 'treatment')

cons_markers_cluster3 <- FindConservedMarkers(integrated_seurat,
                     ident.1 = 3,
                     grouping.var = 'treatment')

```
Let's save this
```{r}
saveRDS(cons_markers_cluster0, file.path(output_path,  "markers_cluster0_bygenotype.rds"))
saveRDS(cons_markers_cluster1, file.path(output_path,  "markers_cluster1_bygenotype.rds"))
saveRDS(cons_markers_cluster2, file.path(output_path,  "markers_cluster2_bygenotype.rds"))
saveRDS(cons_markers_cluster3, file.path(output_path,  "markers_cluster3_bygenotype.rds"))

```

Now let's do Find_all_markers

FindAllMarkers to compare
```{r}

all_markers <- FindAllMarkers(integrated_seurat, logfc.threshold = 0.25, min.pct = 0.25, only.pos = FALSE)

```


Reorder the all_markers and get the top 20 per cluster

```{r}

all_markers_top20 <- all_markers %>% group_by(cluster) %>% slice_max(n = 20, order_by = avg_log2FC)

```

Save everything
```{r}
write.csv(all_markers, file.path(output_path,  "allmarkers.csv"))
write.csv(all_markers_top20, file.path(output_path,  "allmarkers_top20.csv"))
saveRDS(integrated_seurat, file.path(output_path,  "1st_chip_SCTransform_integrated_seurat.rds"))

```


I'm going to try some dotplots to identify gradients

#Canonical Microglia markers

```{r}
#Canonical Microglia markers - I put scale =FALSE so I could see the lower expression of microglia markers

DotPlot(object=integrated_seurat, features=c("C1qa", "Trem2","Tmem119", "Cx3cr1","P2ry12", "P2ry13", "Siglech", "Slc2a5", "Fcrls", "Sall1", "Hexb", "Csf1r" ), dot.scale=10, cols="RdBu", scale=FALSE) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of canonical microglia markers")

DotPlot(object=integrated_seurat, features=c("C1qa", "Trem2","Tmem119", "Cx3cr1","P2ry12", "P2ry13", "Siglech", "Slc2a5", "Fcrls", "Sall1", "Hexb", "Csf1r" ), dot.scale=10, cols="RdBu", scale=TRUE,  split.by = "treatment") + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of canonical microglia markers")
```
# CNS macrophage markers
```{r}
#CNS macrophages
macro <- c("Lyve1", "Cd163", "Siglec1", "Mrc1")

DotPlot(object=integrated_seurat, features=macro, dot.scale=10, cols="RdBu", scale=FALSE) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of CNS macrophage markers")


```
#DAM microglia markers
```{r}
#Using DAM microglia markers

DAM1 <- c("Apoe", "B2m", "Ctsb", "Ctsd", "Cx3cr1", "Fth1", "Lyz2", "P2ry12", "Tmem119", "Tyrobp")

DAM2 <- c("Axl", "Cd9", "Clec7a", "Csf1", "Cst7", "Ctsl", "Itgax", "Lilrb4a", "Lpl", "Timp2", "Trem2")

DAM3 <- c("Cd9", "Itgax", "Clec7a", "Cd63", "Apoe", "B2m", "Tyrobp", "Ctsd", "Lpl", "Cst7", "Trem2", "Ctsb", "Fth1", "Spp1", "Axl", "Ly22", "Igf1", "Gpnmb", "Lilrb4", "Fabp5", "Lgals3")

DotPlot(object=integrated_seurat, features=DAM1, dot.scale=10, cols="RdBu", scale=FALSE) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of DAM1 markers")

DotPlot(object=integrated_seurat, features=DAM2, dot.scale=10, cols="RdBu", scale = FALSE) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of DAM2 markers")

DotPlot(object=integrated_seurat, features=DAM3, dot.scale=10, cols="RdBu", scale = FALSE) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of DAM3 markers")
```
#Cyc-M microglia markers - CPM microglia (cycling and proliferative)

```{r}
#Cyc-M microglia

Cyc_M <- c("Top2a", "Mki67", "Cenpe", "Mcm5", "Birc5", "H2afz", "H2afv")

DotPlot(object=integrated_seurat, features=Cyc_M, dot.scale=10, cols="RdBu", scale=FALSE) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of Cyc_M markers")
```
#Homeostatic microglia markers
```{r}
Homeostatic <- c( "Tgfbr1" , "Smad3", "C1qa", "C1qb", "Cst3", "Csf1r", "Ctsd", "Ctss", "Cx3cr1", "Entpd1", "Fcrls", "Hexb", "Olfml3", "P2ry12", "Tmem119", "Tmsb4x", "Sparc", "Lgmm", "Tppp", "Bin1", "Rgs10", "Gpr34", "Sall1")

DotPlot(object=integrated_seurat, features=Homeostatic, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of Homeostatic microglia markers")


```
#MHC microglia
```{r}
#MHC microglia
MHC <- c("H2-D1", "H2-K1", "H2-Eb1", "H2-Aa","H2-Ab1", "H2-DMa") 

DotPlot(object=integrated_seurat, features=MHC, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of MHC microglia markers")

```
#ARM microglia

```{r}

ARM <- c("Cst7", "Clec7a", "Itgax", "Cd74", "H2-Ab1", "H2-Aa", "Ctsb", "Ctsd", "Spp1", "Gpnmb",  "Dkk2")

DotPlot(object=integrated_seurat, features=ARM, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of ARM microglia markers")
```
#IRM microglia markers
```{r}
IRM <- c("Ifit2", "Ifit3", "Ifitm3", "Irf7", "Oasl2")

DotPlot(object=integrated_seurat, features=IRM, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of IRM microglia markers")
```
#WAM microglia

```{r}

WAM <- c("Stra6l",	"Cxcl13",	"4930556M19Rik",	"Pianp",	"Gpnmb",	"Ch25h",	"Atp6v0d2",	"Mmp12",	"Spp1",	"Ahnak2",	"Itgax",	"Olr1",	"Cst7",	"Gm5424",	"Lpl",	"Pdcd1",	"Apoc1",	"Lox",	"Clec7a",	"Cox6a2",	"Gm44620",	"Postn",	"Olfr110",	"Actr3b",	"St8sia6",	"Igf1",	"Apoe",	"AF529169",	"Axl",	"Rab7b",	"Tnfsf8",	"Cacna1a",	"Ddo",	"Egln3",	"Gas2l3",	"Il1rn",	"Etl4",	"Gm26714",	"Ptchd1")

DotPlot(object=integrated_seurat, features=WAM, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of WAM microglia markers")


```


```{r}

Go_coldresponse <- c("ACADVL",	"ACOT11",	"ADM",	"ADRB1",	"ADRB2",	"APPL2",	"ATP2B1",	"CASP8",	"CDH8",	"CIDEA",	"CIRBP",	"CXCL10",	"DNAJC3",	"EIF2AK3",	"EIF2AK4",	"FOS",	"FOXO1",	"GMPR",	"HSP90AA1",	"HSPA2",	"HSPD1",	"LPL",	"LRP11",	"METRNL",	"MT-CO2",	"MTCO2P12",	"NFE2L1",	"NFKBIA",	"P2RX3",	"PCSK1N",	"PLAC8",	"PPARG",	"PPARGC1A",	"PRKAA1",	"RNF34",	"SAXO1",	"SLC25A27",	"SLC27A1",	"SLC9A1",	"THRA",	"TMEM135",	"TRPA1",	"TRPM8",	"UCP1",	"UCP2",	"UCP32",	"VGF",	"ZNF516"
)

Go_coldresponse <- sapply(Go_coldresponse, mouse_ID)
 
DotPlot(object=integrated_seurat, features=Go_coldresponse, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of Go-cold response genes")

``` 
PIG microglia (Chen et al., 2020) https://www.sciencedirect.com/science/article/pii/S0092867420308151#mmc3

#PIG microglia
```{r}
#PIG microglia - Plaque induced genes

PIG1 <- c("Apoe", "Arpc1b", "Axl", "B2m", "C1qa", "C1qb", "C1qc", "C4a", "C4b", "Cd63", "Cd63-ps", "Cd9", "Clu", "Csf1r", "Cst3", "Ctsa", "Ctsb", "Ctsd", "Ctsh", "Ctsl", "Ctss")
PIG2 <- c("Ctsz", "Cx3cr1", "Cyba", "Fcer1g", "Fcgr3", "Fcrls", "Gfap", "Gns", "Gpx4", "Grn", "Gusb", "H2-D1", "H2-K1", "Hexa", "Hexb", "Igfbp5", "Itgb5", "Itm2b", "Laptm5", "Lgals3bp")
PIG3 <- c("Lgmn", "Ly86", "Lyz2", "Man2b1", "Mpeg1", "Npc2", "Olfml3", "Plek", "Prdx6", "RP23-269H21.1", "Rpl18a", "S100a6", "Serpina3n", "Trem2", "Tyrobp", "Vsir")

DotPlot(object=integrated_seurat, features=PIG, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of Plaque induced genes")

DotPlot(object=integrated_seurat, features=PIG1, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of Plaque induced genes")
DotPlot(object=integrated_seurat, features=PIG2, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of Plaque induced genes")
DotPlot(object=integrated_seurat, features=PIG3, dot.scale=10, cols="RdBu", scale=FALSE) + theme(text = element_text(size = 10)) + theme(axis.text.x = element_text(size = 12)) +  theme(axis.text.x = element_text(angle = 45, hjust=1)) + ggtitle("Expression of Plaque induced genes")


```

```{r}
library(scCustomize)
# Set color palette
pal <- viridis(n = 10, option = "C", direction = -1)
FeaturePlot_scCustom(seurat_object = integrated_seurat, features = "Csf1r", colors_use = pal, order=FALSE)
FeaturePlot_scCustom(seurat_object = integrated_seurat, features = "Csf1r", colors_use = pal, order=TRUE)
```
#Because I forgot get the microglia subtypes per treatment (genotyped)

```{r}
#Per treatment = genotype
cluster_genotype <- table(integrated_seurat$singlr_sierksma, integrated_seurat$treatment)
cluster_genotype_df <- as.data.frame.matrix(cluster_genotype)
print(cluster_genotype_df)

#Per treatment=genotype per cluster

cluster_genotype_cluster <- table(integrated_seurat$seurat_clusters, integrated_seurat$singlr_sierksma, integrated_seurat$treatment)
cluster_genotype_cluster_df <- as.data.frame(cluster_genotype_cluster)
print(cluster_genotype_cluster_df)

```

I'm happy to call cluster3 -  MHC high microglia and cluster 0 - Microglia.1, cluster1 - Microglia.2 and cluster2 - Microglia.3

#Let's set the idents

```{r}
integrated_seurat <- RenameIdents(integrated_seurat, `0` = "Microglia.1", `1` = "Microglia.2", `2` = "Microglia.3", `3` = "MHC high Microglia")

p4 <- DimPlot(integrated_seurat, reduction = "umap", label = TRUE, label.size=3) + ggtitle ("Seurat clusters")
p4 <- p4 + theme(legend.text = element_text(size = 10))
print(p4)
pdf("results/1st_Syk_chip/Marieta_1stchip_RenamedSeurat_clusters.pdf", width = 7, height = 5)
print(p4)
dev.off()
```
#pseudobulk DE analysis - DE can also be done with FindMarkers for all cells by condition but this is NOT recomended - cells are not independent and we'll therefore artificially inflating N which will wrongfully inflate p-values

-However pseudobulk analysis can be performed in Seurat with

Seurat::AggregateExpression(seurat_object, group.by = "celltype_x_sample", return.seurat = TRUE) before sub-setting and using FindMarkers.

Note - sctransform v2 allows to do DE on SCTranform residuals directly. I think this would be quite hard to interpret so I'm not doing this all with do standard pseudobulk instead

```{r}
integrated_seurat$idents <- Idents(integrated_seurat)

```

#Aggregate the data
```{r}
# Extract raw counts and metadata to create SingleCellExperiment object
counts <- integrated_seurat@assays$RNA@counts 

metadata <- integrated_seurat@meta.data

# Set up metadata as desired for aggregation and DE analysis
metadata$cluster_id <- factor(integrated_seurat@active.ident)

# Create single cell experiment object
sce <- SingleCellExperiment(assays = list(counts = counts), 
                           colData = metadata)
```

#Aggregation by cell type in Sample
```{r}
# Extract unique names of clusters (= levels of cluster_id factor variable)
cluster_names <- levels(colData(sce)$cluster_id)
cluster_names

# Total number of clusters
length(cluster_names)
```

```{r}
# Extract unique names of samples (= levels of sample_id factor variable)
colData(sce)$Sample <- as.factor(colData(sce)$Sample)
sample_names <- levels(colData(sce)$Sample)
sample_names

# Total number of samples
length(sample_names)
```
#Aggregation of counts is performed to the sample level - we want one aggregated counts data matrix per cluster (cell type), with each data matrix listing all genes as rows and all 4 samples as columns.

```{r}
# Subset metadata to include only the variables you want to aggregate across (here, we want to aggregate by sample and by cluster)
groups <- colData(sce)[, c("cluster_id", "Sample")]
head(groups)
```

```{r}
# Aggregate across cluster-sample groups
# transposing row/columns to have cell_ids as row names matching those of groups
#remotes::install_github("cvarrichio/Matrix.utils")
library(Matrix.utils)
aggr_counts <- aggregate.Matrix(t(counts(sce)), 
                                groupings = groups, fun = "sum") 

# Explore output matrix
class(aggr_counts)
dim(aggr_counts)
aggr_counts[1:6, 1:6]
```

The output of this aggregation is a sparse matrix with genes as columns and cell type/sample combinations as rows.

#Splitting the counts matrix by cell type

To perform DE analysis on a per cell type basis, we still need to:

Transform the matrix back, so that the genes are listed in rows and the samples are in columns

Split our matrix by cell type

```{r}
# Transpose aggregated matrix to have genes as rows and samples as columns
aggr_counts <- t(aggr_counts)
aggr_counts[1:6, 1:6]

```
# Split by sample

I'm using tstrsplit() function to split our cell type_sample string by â€œ_â€, which will separate the string into cell type and sample

```{r}
# Loop over all cell types to extract corresponding counts, and store information in a list
library(data.table)
## Initiate empty list
counts_ls <- list()

for (i in 1:length(cluster_names)) {

  ## Extract indexes of columns in the global matrix that match a given cluster
  column_idx <- which(tstrsplit(colnames(aggr_counts), "_")[[1]] == cluster_names[i])
  
  ## Store corresponding sub-matrix as one element of a list
  counts_ls[[i]] <- aggr_counts[, column_idx]
  names(counts_ls)[i] <- cluster_names[i]

}

# Explore the different components of the list
str(counts_ls)

```
#Generate matching metadata
```{r}
metadata <- colData(sce) %>% 
  as.data.frame() %>% 
  dplyr::select(Sample, treatment)

dim(metadata)
head(metadata)

# Exclude duplicated rows
metadata <- metadata[!duplicated(metadata), ]

dim(metadata)
head(metadata)
```
```{r}
rownames(metadata) <- metadata$Sample
head(metadata)
```
#If you want to add batch, age etc now would be the time to do so
```{r}
metadata$batch = "1st_Syk_chip"
metadata$Age = "10w"
metadata$Sex = "Male"
head(metadata)
```

#No of cells per sample and cluster
```{r}
t <- table(colData(sce)$Sample,
           colData(sce)$cluster_id)

t
```
#Append cell count to metadata and split metadata by cell-type
```{r}
library(stringr)
## Initiate empty list
metadata_ls <- list()

for (i in 1:length(counts_ls)) {
  
    ## Initiate a data frame for cluster i with one row per sample (matching column names in the counts matrix)
    df <- data.frame(cluster_sample_id = colnames(counts_ls[[i]]))
    
    ## Use tstrsplit() to separate cluster (cell type) and sample IDs
    split_result <- tstrsplit(df$cluster_sample_id, "_")
    df$cluster_id <- tstrsplit(df$cluster_sample_id, "_")[[1]]
    df$Sample <- str_extract(df$cluster_sample_id, "(?<=_).*")
    
    ## Retrieve cell count information for this cluster from global cell count table
    idx <- which(colnames(t) == unique(df$cluster_id))
    cell_counts <- t[, idx]
    
    ## Remove samples with zero cell contributing to the cluster
    cell_counts <- cell_counts[cell_counts > 0]
    
    ## Match order of cell_counts and sample_ids
    sample_order <- match(df$Sample, names(cell_counts))
    cell_counts <- cell_counts[sample_order]
    
    ## Append cell_counts to data frame
    df$cell_count <- cell_counts
    
    
    ## Join data frame (capturing metadata specific to cluster) to generic metadata
df <- plyr::join(df, metadata, by = intersect(names(df), names(metadata)))
    
    ## Update rownames of metadata to match colnames of count matrix, as needed later for DE
    rownames(df) <- df$cluster_sample_id
    
    ## Store complete metadata for cluster i in list
    metadata_ls[[i]] <- df
    names(metadata_ls)[i] <- unique(df$cluster_id)

}

# Explore the different components of the list
str(metadata_ls)

```

## EdgeR

- DE analysis with [EdgeR quasi-likeliehood dispersions](https://bioconductor.org/packages/devel/workflows/vignettes/RnaSeqGeneEdgeRQL/inst/doc/edgeRQL.html), can handle biological variation between replicates in each sample group, e.g. WT vs Mutant.

### Pseudo-bulk by Cluster

- Reformat data for pseudo-bulk by summing counts together for all cells with the same combination of label and sample
- Input should be reconstructed counts or counts.

### Step-by-Step for 1 Cluster

- Not all cluster labels are used for generating this coefficient, as a strong DE between labels or batch effects would prevent a sensible model from being calculated.

```{r}
# Select cell type of interest
cluster_names

# Double-check that both lists have same names
all(names(counts_ls) == names(metadata_ls))

```
#EdgeR DE Step by step for Microglia.1

```{r}
idx <- which(names(counts_ls) == "Microglia.1")
cluster_counts <- counts_ls[[idx]]
cluster_metadata <- metadata_ls[[idx]]

```

As sanity test ensure extracted data matches

```{r}
# Check matching of matrix columns and metadata rows
all(colnames(cluster_counts) == rownames(cluster_metadata))
```

```{r}
y <- DGEList(cluster_counts, samples=cluster_metadata)

```

- Remove samples with low library size e.g. sample contributing \< 10 cells to a cluster won't be informative.

```{r}
#| label: filt_count

discarded <- cluster_metadata$cell_count < 10
y <- y[,!discarded]
summary(discarded)
```

- Remove genes that are lowly expressed to improve accuracy of the pseudo-bulk modelling.
- The `filterByExpr` function discards genes below a log-CPM threshold in a minimum number of samples (based on smallest group size)

```{r}
#| label: filt_expr

keep <- filterByExpr(y, group = cluster_metadata$Sample)
y <- y[keep,]
summary(keep)
```

- Correct for composition biases (e.g. caused by different sequencing depths) by calculating a [scaling factor](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-3-r25) for the library size with the `calcNormFactors` function.

```{r}
#| label: calc_NormFactors

y <- calcNormFactors(y)
y$samples
```

- Check the pseudo-bulk profile has been normalised using a mean-difference plot.
  - Should see a trumpet shape centered at zero.
  - If there is no zero-centering or discrete patterns at low logCPM values then indicates a normalisation issue likely caused by a lack of cells/reads in one profile.

```{r}
#| label: MD_plot
#| fig-width: 9
#| fig-height: 4

par(mfrow=c(2,3))
for(i in seq_len(ncol(y))){
  plotMD(y, column = i)
}
```

- Check similarity between the transcriptomes are between the different samples with a multi-dimensional scaling plot (similar principles to a PCA plot).
  - Requires sample number to be **\> 2**.

```{r}
#| label: MDS_plot
#| fig-height: 3.5
#| fig-width: 4

plotMDS.DGEList(y, col = as.numeric(y$samples$Sample))
```

- Testing if the log-fold change between sample groups is significantly different from zero.
  - You will need to alter the design of the model matrix for **your** experimental question.
- Estimate the negative binomial dispersions with `estimateDisp()`
- Plot indicates the the biological coefficent of variation where each dot indicates a gene.

```{r}
#| label: NB_disp

# Test design
design <- model.matrix(~ treatment, y$samples)
design
```

```{r}

# Estimate negative binomial dispersions
y <- estimateDisp(y, design)
summary(y$trended.dispersion)

# Plot Biological coefficient of Variation
plotBCV(y)
```

- A complementary measure of variance is the quasi-likelihood dispersions, estimated with the `glmQLFit` function.
- This model looks at the uncertainty and variability of the per-gene variance.

```{r}
#| label: QL_disp

fit <- glmQLFit(y, design, robust = TRUE)
summary(fit$var.prior)

plotQLDisp(fit)
```

- Test for differences in expression due to sample group, DEGs are defined as having a lfc that isn't zero at a FDR rate of 5%.
- A large number of non-significant DEGs suggest sample group is having little impact on the transcriptome.

```{r}
#| label: QLF_test
# A positive FC is increased expression in the treated compared to control
# Create contrasts

res <- glmQLFTest(fit, coef = ncol(design))

# Summary table of DEGs
summary(decideTests(res))

# Gene names and FDR values for the investigated cluster
topTags(res, n = Inf, sort.by = "p.value")$table

#rm(countsToUse, current, fit, res, y, columnsToUse, i, discarded, keep, labelToGet, tab)
```

### Looping across Clusters

- Using the `pseudobulkDGE` function this process will be repeated for all the other clusters.
  - Won't suit all experimental designs *clusters will need to consist of 2 or more sample groups*
- Apply a common design matrix that will be used in the analysis for each cluster/label.
  - Adjust the factor(s) to fit your experimental design.
  - Defaults the baseline as the 1st label alphabetically, can use `relevel` command to reorder factors if desired.
- Output will be a list of DEG for each cluster, investigate dataframes with `de.results[["x"]]`
- Clusters with low replicates or it only exists in one condition will be skipped, use `metadata(de.results)$failed` command to investigate.

```{r}
# Empty list to store the results for all clusters
de_results_list <- list()


# Loop through the clusters
for (i in 1:length(metadata_ls)) {
  # Get metadata and counts for the current cluster
  metadata_DE <- metadata_ls[[i]]
  counts_DE <- counts_ls[[i]]

  #Filter out clusters with insufficient cells (< 5) , I lowered this to 5 do I can also include MHC high cluster
  filtered_counts <- counts_DE[,metadata_DE$cell_count >= 5, ]
  filtered_metadata <- metadata_DE[metadata_DE$cell_count >= 5, ]


  # Apply the `pseudoBulkDGE` function to obtain DE genes for the current cluster
  filtered_metadata$treatment <- factor(filtered_metadata$treatment)
  
  de_results <- scran::pseudoBulkDGE(filtered_counts, col.data=filtered_metadata, label = filtered_metadata$cluster_id, design = ~0 + treatment, coef = "treatmentTreated", condition =filtered_metadata$treatment)
 
   # Store the results for the current cluster in the list
  de_results_list[[i]] <- de_results
}

# Combine the results for all clusters into a single dataframe
de_results_df <- data.frame(de_results_list)
 
```

- Examine the DEGs at a FDR of 5% for each cluster/label using the `decideTestsPerLabel` function.
 - NA indicates low expression or comparison wasn't possible.
 - Down-regulated genes are in the *-1* column, up-regulated in *+1* and *0* indicates no significant changes.
 
 
```{r}

# Apply decideTestsPerLabel and summarizeTestsPerLabel to each test result
is.de <- lapply(de_results_list, function(x) {
  de_results <- decideTestsPerLabel(x, threshold = 0.05, pval.field = "PValue")
  summarize_results <- summarizeTestsPerLabel(de_results)
  return(summarize_results)
})
# Print the results summary
is.de
```
- You can then determine the proportion of clusters/cell-types in which the DEGs are present for both up- and down-regulated genes.
  - If you would prefer to view the data as volcano plots you can use the code from the DESeq2 analysis.

```{r}
#| label: Universal_DEGs
#| eval: false

# Upregulated across most cell types.
up.de <- lapply(is.de, function(x) x > 0 & !is.na(x))
row_means <- sapply(up.de, rowMeans)
top_genes <- head(sort(row_means, decreasing = TRUE), 10)

# Downregulated across cell types.
down.de <- lapply(is.de, function(x) x < 0 & !is.na(x))
row_means <- sapply(down.de, rowMeans)
top_genes <- head(sort(row_means, decreasing = TRUE), 10)

```

```{r}
# Count the number of TRUE values in up.de
num_true <- sum(up.de == TRUE)

# Print the result
print(num_true)

# Count the number of TRUE values in down.de
num_true <- sum(down.de == TRUE)

# Print the result
print(num_true)
```
- A list of cluster/label-specific DEGs:

```{r}
#| label: Specific_DEGs
#| eval: false

# First generate an extremely "unlikely" DEG the FDR is relaxed to 50%, i.e. If it isn't significant at a 50% false-positive rate then is not considered DE expressed.
remotely.de <- lapply(de_results_list, function(x) decideTestsPerLabel(x, threshold = 0.5, pval.field = "PValue"))
not.de <- lapply(remotely.de, function(x) x == 0 | is.na(x))

# Subset the data to investigate one cluster of interest
cx <- is.de[[1]]

# List the other clusters in the dataset
other.labels <- setdiff(names(not.de), names(cx))

# Select DEGs that are DE in the cluster of interest only
unique.degs <- unlist(lapply(seq_along(is.de), function(i) {
  is_de_cluster <- is.de[[i]]
  not_de_other <- not.de[[i]][, other.labels]
  is_de_cluster != 0 & rowMeans(not_de_other == 1)
}))
unique.degs <- names(which(unique.degs))
head(unique.degs)

```

- A Plot of the most DEG unique to cluster set as `cx` export desired results as csv files (can copy code from above)

```{r}
#| label: plot_DEGs
#| eval: false

# Plotting expression levels
de.inspec <- list()
de.inspec[[cx]] <- de.results[[cx]]
de.inspec[[cx]] <- de.inspec[[cx]][order(de.inspec[[cx]]$PValue),]
de.inspec[[cx]] <- de.inspec[[cx]][rownames(de.inspec[[cx]]) %in% unique.degs,]

sizeFactors(summed.filt) <- NULL

plotExpression(logNormCounts(summed.filt),
               features = rownames(de.inspec[[cx]])[1],
               x="Sample", colour_by ="treatment",
               other_fields = "louvain")+
              facet_wrap(~louvain)+
              ggtitle(glue::glue("{cx}: {rownames(de.inspec[[cx]])[1]}"))

```


## DESeq2

- Another popular method of calculating DEGs [DESeq2](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html)
- This DE comparison is based on un-normalised count data.
- Adjust the analysis design to fit your experimental question, this can be multifactoral.
- The `DESeq` function is a wrapper for estimation of size factors, estimation of dispersions and negative binomical GLM fitting.

```{r}
#I'm recycling counts_ls and metadata_ls and I'm testing Microglia.1 first like I did with edgeR

idx <- which(names(counts_ls) == "Microglia.1")
cluster_counts <- counts_ls[[idx]]
cluster_metadata <- metadata_ls[[idx]]

```

```{r}
#Check they were correctly subsetted

all(colnames(cluster_counts) == rownames(cluster_metadata))

```
# Create DESeq2 object 

```{r}
dds <- DESeqDataSetFromMatrix(cluster_counts, 
                              colData = cluster_metadata, 
                              design = ~ treatment)

```
#Perform sample level quality control

```{r}
# Transform counts for data visualization
rld <- rlog(dds, blind=TRUE)

# Plot PCA
DESeq2::plotPCA(rld, ntop = 500, intgroup = "treatment")

```
```{r}
DESeq2::plotPCA(rld, ntop = 500, intgroup = "cell_count")

```
PCA coloured by number of cells per sample

#Check hierarchical clustering

```{r}
# Extract the rlog matrix from the object and compute pairwise correlation values
rld_mat <- assay(rld)
rld_cor <- cor(rld_mat)

# Plot heatmap
pheatmap(rld_cor, annotation = cluster_metadata[, c("treatment"), drop=F], cluster_rows=F, cluster_cols=F)
```
This is a very limited QC but with 2 samples in each group there isn't much that can be done. Im going ahead with the DESeq DE

#Note - we are still only working with Microglia.1
```{r}
# Run DESeq2 differential expression analysis
dds <- DESeq(dds)

```
#Check the fit of the model

```{r}
# Plot dispersion estimates
plotDispEsts(dds)

```
This look quite reasonable actually - dispersions decrease with increasing mean and kind of follow the line of best fit (in red)

#Getting the DE results for Microglia.1

```{r}
# Check the coefficients for the comparison - we want treated in comparison with control
resultsNames(dds)

# Generate results object
res <- results(dds, 
               name = "treatment_Treated_vs_Control",
               alpha = 0.05)

# Shrink the log2 fold changes to be easier to interpret using the apeglm method - 
#**Note** cite Zhu et al., 2018 when using this method
res <- lfcShrink(dds, 
                 coef = "treatment_Treated_vs_Control",
                 res=res,
                 type = "apeglm")

```
```{r}
# Turn the DESeq2 results into a tibble 
res_tbl <- res %>%
  data.frame() %>%
  rownames_to_column(var = "gene") %>%
  as_tibble() %>%
  arrange(padj)

# Check results output
res_tbl 

# Write all results to file
write.csv(res_tbl,
          paste0("results/", unique(cluster_metadata$cluster_id), "_", 
                 levels(as.factor(cluster_metadata$treatment))[2], "_vs_", levels(as.factor(cluster_metadata$treatment))[1], "_all_genes.csv"),
          quote = FALSE, 
          row.names = FALSE)
```
#Filter table to significant genes on p-value
```{r}
# Set thresholds
padj_cutoff <- 0.05

# Subset the significant results
sig_res <- dplyr::filter(res_tbl, padj < padj_cutoff) %>%
  dplyr::arrange(padj)

# Check significant genes output
sig_res

# Write significant results to file
write.csv(res_tbl,
          paste0("results/", unique(cluster_metadata$cluster_id), "_", 
                 levels(as.factor(cluster_metadata$treatment))[2], "_vs_", levels(as.factor(cluster_metadata$treatment))[1], "_signif_genes.csv"),
          quote = FALSE, 
          row.names = FALSE)

```

Scatterplot of normalized expression of top 20 most significant genes

- This plot is a good check to make sure that we are interpreting our fold change values correctly, as well.

# Scatterplot

```{r}
## Extract normalized counts from dds object
normalized_counts <- counts(dds, normalized = TRUE)

## Extract top 20 DEG from resLFC (make sure to order by padj)
top20_sig_genes <- sig_res %>%
  dplyr::arrange(padj) %>%
  dplyr::pull(gene) %>%
  head(n = 20)

## Extract matching normalized count values from matrix
top20_sig_counts <- normalized_counts[rownames(normalized_counts) %in% top20_sig_genes, ]
top20_sig_counts

## Convert wide matrix to long data frame for ggplot2
top20_sig_df <- data.frame(top20_sig_counts)
top20_sig_df$gene <- rownames(top20_sig_counts)

top20_sig_df <- melt(setDT(top20_sig_df), 
                     id.vars = c("gene"),
                     variable.name = "cluster_sample_id") %>% 
  data.frame()


## Join counts data frame with metadata
top20_sig_df <- plyr::join(top20_sig_df, as.data.frame(colData(dds)),
                           by = "cluster_sample_id")
top20_sig_df

## Generate plot
ggplot(top20_sig_df, aes(y = value, x = treatment, col = treatment)) +
  geom_jitter(height = 0, width = 0.15) +
  scale_y_continuous(trans = 'log10') +
  ylab("log10 of normalized expression level") +
  xlab("condition") +
  ggtitle("Top 20 Significant DE Genes") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ gene)
```
Plot the combined top20 genes

```{r}
## plot using ggplot2
ggplot(top20_sig_df) +
        geom_point(aes(x = gene, 
                       y = value, 
                       color = treatment), 
                   position=position_jitter(w=0.1,h=0)) +
        scale_y_log10() +
        xlab("Genes") +
        ylab("log10 Normalized Counts") +
        ggtitle("Top 20 Significant DE Genes") +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
        theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = c("#404040", "#6CA6CD"))

```
#Heatmap of all significant genes

```{r}
# Heatmap

## Extract normalized counts for significant genes only
sig_counts <- normalized_counts[rownames(normalized_counts) %in% sig_res$gene, ]

## Set a color-blind friendly palette
heat_colors <- rev(brewer.pal(11, "PuOr"))

## Run pheatmap using the metadata data frame for the annotation
pheatmap(sig_counts, 
         color = heat_colors, 
         cluster_rows = TRUE, 
         show_rownames = FALSE,
         annotation = cluster_metadata[, c("treatment", "cluster_id")], 
         border_color = NA, 
         fontsize = 10, 
         scale = "row", 
         fontsize_row = 10, 
         height = 20)  

```
#Volcano plots

```{r}
#For log2FC = 0
log2fc_cutoff <- 0
# Volcano plot
res_table_thres <- res_tbl[!is.na(res_tbl$padj), ] %>% 
  mutate(threshold = padj < padj_cutoff & abs(log2FoldChange) >= log2fc_cutoff)
min(log10(res_table_thres$padj))

## Generate plot
ggplot(res_table_thres) +
  geom_point(aes(x = log2FoldChange, y = -log10(padj), colour = threshold)) +
  ggtitle("Volcano plot of treated Microglia.1 cells relative to control") +
  xlab("log2 fold change") +
  xlim(-2, 12) +
  ylab("-log10 adjusted p-value") +
  scale_y_continuous(limits = c(0, 5)) +
  scale_color_manual(values = c("grey60", "red3")) +
  theme(legend.position = "none",
        plot.title = element_text(size = rel(1.3), hjust = 0.5),
        axis.title = element_text(size = rel(1.15)))                    
```
What an ugly plot , I'm redoing this with enhancedvolcanoplot later

#Do DE for all clusters

```{r}
# Create directories to save results if they don't already exist:
if (!dir.exists("DESeq2")) { dir.create("DESeq2") }
if (!dir.exists("DESeq2/pairwise")) { dir.create("DESeq2/pairwise") }
setwd("DESeq2/pairwise/")


# Function to run DESeq2 Wald Test and get results for any cluster:
## clustx is the name of the cluster (cell type) on which to run the function
## A is the sample group to compare (e.g. treated condition)
## B is the sample group to compare against (base/control level)
## padj_cutoff defines the adjusted p-value cutoff for significance (set to 0.05 by default)

## This function assumes the counts matrices and metadata for all clusters have been prepared and arranged in matching named lists

## This function assumes the contrast (e.g. stim vs. control) is stored in a variable named "treatment"


get_dds_resultsAvsB <- function(clustx, A, B, padj_cutoff = 0.05) {
  
  print(clustx) 
  
  # Extract counts matrix and metadata for cluster x
  idx <- which(names(counts_ls) == clustx)
  cluster_counts <- counts_ls[[idx]]
  cluster_metadata <- metadata_ls[[idx]]
  
  # Print error message if sample names do not match
  if ( all(colnames(cluster_counts) != rownames(cluster_metadata)) ) {
    print("ERROR: sample names in counts matrix columns and metadata rows do not match!")
  }
  
  dds <- DESeqDataSetFromMatrix(cluster_counts, 
                                colData = cluster_metadata, 
                                design = ~ treatment)
  
  # Transform counts for data visualization
  rld <- rlog(dds, blind = TRUE)
  
  
  # Generate QC plots
  
  ## Plot and save PCA plot
  DESeq2::plotPCA(rld, intgroup = "treatment")
  if (!dir.exists("results")) { dir.create("results") }
  ggsave(paste0("results/", clustx, "_specific_PCAplot.png"))
  
  ## Extract rlog matrix from the object and compute pairwise correlation values
  rld_mat <- assay(rld)
  rld_cor <- cor(rld_mat)
  
  ## Plot and save heatmap
  png(paste0("results/", clustx, "_specific_heatmap.png"),
      height = 6, width = 7.5, units = "in", res = 300)
    pheatmap(rld_cor, annotation = cluster_metadata[, c("treatment"), drop = FALSE])
  dev.off()
  
  
  # Run DESeq2 differential expression analysis
  dds <- DESeq(dds)
  
  ## Plot dispersion estimates
  png(paste0("results/", clustx, "_dispersion_plot.png"),
      height = 5, width = 6, units = "in", res = 300)
    plotDispEsts(dds)
  dev.off()
  
  ## Output and shrink results of Wald test for contrast A vs B
  contrast <- paste(c("treatment", A, "vs", B), collapse = "_")
  # resultsNames(dds)
  
  res <- results(dds, name = contrast, alpha = 0.05)
  res <- lfcShrink(dds, coef = contrast, res = res)
  
  ## Turn the results object into a tibble for use with tidyverse functions
  res_tbl <- res %>%
    data.frame() %>%
    rownames_to_column(var = "gene") %>%
    as_tibble()
  
  write.csv(res_tbl,
            paste0("results/", clustx, "_", contrast, "_all_genes.csv"),
            quote = FALSE, 
            row.names = FALSE)
  
  ## Subset the significant results
  sig_res <- dplyr::filter(res_tbl, padj < padj_cutoff) %>%
    dplyr::arrange(padj)
  
  write.csv(sig_res,
            paste0("results/", clustx, "_", contrast, "_signif_genes.csv"),
            quote = FALSE, 
            row.names = FALSE)
  
  
  # Generate results visualization plots
  
  ## Extract normalized counts from dds object
  normalized_counts <- counts(dds, normalized = TRUE)
  
  ## Extract top 20 DEG from sing_res by padj (make sure to order by padj)
  top20_pvalue <-  sig_res %>% arrange(padj) %>% slice_head(n = 20)
  
  #Save top20_pvalue
  write.csv(top20_pvalue,
            paste0("results/", clustx, "_", contrast, "_top20_pvalue.csv"),
            quote = FALSE, 
            row.names = FALSE)
  
  
  ## Extract matching normalized count values from matrix
  top20_sig_counts <- normalized_counts[rownames(normalized_counts) %in% top20_pvalue$gene, ]
  
  ## Convert wide matrix to long data frame for ggplot2
  top20_sig_df <- data.frame(top20_sig_counts)
  top20_sig_df$gene <- rownames(top20_sig_df)
  
  top20_sig_df <- melt(setDT(top20_sig_df), 
                       id.vars = c("gene"),
                       variable.name = "cluster_sample_id") %>% 
    data.frame()
  

  ##For MHC high microglia only - need to correct this manually run the code that's hashed out
  ## Replace "." by " " in cluster_sample_id variable (melt() introduced the ".")
 # top20_sig_df$cluster_sample_id <- gsub("\\.", " ", top20_sig_df$cluster_sample_id)
  #top20_sig_df$cluster_sample_id <- gsub("\\  ", "+ ", top20_sig_df$cluster_sample_id)
  
  ## Join counts data frame with metadata
  top20_sig_df <- plyr::join(top20_sig_df, as.data.frame(colData(dds)),
                             by = "cluster_sample_id")
  
  ## plot using ggplot2
ggplot(top20_sig_df) +
        geom_point(aes(x = gene, 
                       y = value, 
                       color = treatment), 
                   position=position_jitter(w=0.1,h=0)) +
        scale_y_log10() +
        xlab("Genes") +
        ylab("log10 Normalized Counts") +
        ggtitle("Top 20 Significant DE Genes (p-value)") +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
        theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = c("#404040", "#6CA6CD"))

  
  ggsave(paste0("results/", clustx, "_", contrast, "_top20_DE_pvalue_genes.png"))

  ## Extract top 20 DEG from resLFC by FC (make sure to order by FC)
  top20_FC <- sig_res %>% arrange(desc(abs(log2FoldChange))) %>% slice_head(n = 20)
  
  #Save top20_pvalue
  write.csv(top20_FC,
            paste0("results/", clustx, "_", contrast, "_top20_FC.csv"),
            quote = FALSE, 
            row.names = FALSE)
  
  ## Extract matching normalized count values from matrix
  top20_sig_counts <- normalized_counts[rownames(normalized_counts) %in% top20_FC$gene, ]
  
  ## Convert wide matrix to long data frame for ggplot2
  top20_sig_df <- data.frame(top20_sig_counts)
  top20_sig_df$gene <- rownames(top20_sig_df)
  
  top20_sig_df <- melt(setDT(top20_sig_df), 
                       id.vars = c("gene"),
                       variable.name = "cluster_sample_id") %>% 
    data.frame()
  
##For MHC high microglia only - need to correct this manually run the code that's hashed out
  ## Replace "." by " " in cluster_sample_id variable (melt() introduced the ".")
 # top20_sig_df$cluster_sample_id <- gsub("\\.", " ", top20_sig_df$cluster_sample_id)
  #top20_sig_df$cluster_sample_id <- gsub("\\  ", "+ ", top20_sig_df$cluster_sample_id)
  
  ## Join counts data frame with metadata
  top20_sig_df <- plyr::join(top20_sig_df, as.data.frame(colData(dds)),
                             by = "cluster_sample_id")
  
  ## plot using ggplot2
ggplot(top20_sig_df) +
        geom_point(aes(x = gene, 
                       y = value, 
                       color = treatment), 
                   position=position_jitter(w=0.1,h=0)) +
        scale_y_log10() +
        xlab("Genes") +
        ylab("log10 Normalized Counts") +
        ggtitle("Top 20 Significant DE Genes (FC)") +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
        theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = c("#404040", "#6CA6CD"))

  
  ggsave(paste0("results/", clustx, "_", contrast, "_top20_DE_FC_genes.png"))  
  
}

# Run the script on all clusters comparing stimulated condition relative to control condition
map(cluster_names, get_dds_resultsAvsB, A = "Treated", B = "Control")

```
#Heatmaps for all significant genes by cluster
```{r, warning=FALSE}
# Heatmap
padj_cutoff <- 0.05

# Loop through the clusters
for (i in 1:length(metadata_ls)) {
  # Get metadata and counts for the current cluster
  cluster_counts <- counts_ls[[i]]
  cluster_metadata <- metadata_ls[[i]]
  
  dds <- DESeqDataSetFromMatrix(cluster_counts, 
                                colData = cluster_metadata, 
                                design = ~ treatment)
# Run DESeq2 differential expression analysis
  dds <- DESeq(dds)

  # resultsNames(dds)
  contrast <- paste(c("treatment", "Treated", "vs", "Control"), collapse = "_")
  
  
  res <- results(dds, name = contrast, alpha = 0.05)
  res <- lfcShrink(dds, coef = contrast, res = res)
  
   ## Turn the results object into a tibble for use with tidyverse functions
  res_tbl <- res %>%
    data.frame() %>%
    rownames_to_column(var = "gene") %>%
    as_tibble()
  
# Subset the significant results
  sig_res <- dplyr::filter(res_tbl, padj < padj_cutoff) %>%
    dplyr::arrange(padj)
  
  
  # Generate results visualization plots
  
  ## Extract normalized counts from dds object
  normalized_counts <- counts(dds, normalized = TRUE)
  
  ## Extract normalized counts for significant genes only
sig_counts <- normalized_counts[rownames(normalized_counts) %in% sig_res$gene, ]
  

# Define the colors
heat_colors <- heat_colors <- rev(brewer.pal(11, "PuOr"))

## Run pheatmap using the metadata data frame for the annotation
pheatmap(sig_counts, 
         color = heat_colors, 
         cluster_rows = TRUE, 
         show_rownames = FALSE,
         annotation = cluster_metadata[, c("treatment", "cluster_id")], 
         cellheight = 0.5,
         border_color = NA, 
         fontsize = 10,
         scale = "row", 
         fontsize_row = 10, 
         height = 20)  

}
```

#Volcano plots

```{r}
library(EnhancedVolcano)

#p-value as log
p <- 0.05 
logp <- -log10(p)

Microglia.1 <- read.csv("DESeq2/pairwise/results/Microglia.1_treatment_Treated_vs_Control_all_genes.csv", sep=",")
Microglia.2 <- read.csv("DESeq2/pairwise/results/Microglia.2_treatment_Treated_vs_Control_all_genes.csv", sep=",")
Microglia.3 <- read.csv("DESeq2/pairwise/results/Microglia.3_treatment_Treated_vs_Control_all_genes.csv", sep=",")
MHC.high.Microglia <- read.csv("DESeq2/pairwise/results/MHC high Microglia_treatment_Treated_vs_Control_all_genes.csv", sep=",")


#Microglia.1
Graph_Microglia.1 <- Microglia.1[c('gene', 'log2FoldChange', 'padj')]
Graph_Microglia.1 <- Graph_Microglia.1[!is.na(Graph_Microglia.1$padj), ]
#Microglia.2
Graph_Microglia.2 <- Microglia.2[c('gene', 'log2FoldChange', 'padj')]
Graph_Microglia.2 <- Graph_Microglia.2[!is.na(Graph_Microglia.2$padj), ]
#Microglia.3
Graph_Microglia.3 <- Microglia.3[c('gene', 'log2FoldChange', 'padj')]
Graph_Microglia.3 <- Graph_Microglia.3[!is.na(Graph_Microglia.3$padj), ]
#MHC High Microglia
Graph_MHC.high.Microglia <- MHC.high.Microglia[c('gene', 'log2FoldChange', 'padj')]
Graph_MHC.high.Microglia <- Graph_MHC.high.Microglia[!is.na(Graph_MHC.high.Microglia$padj), ]
```

```{r}
#Make Numeric if needed
str(Graph_Microglia.1)
str(Graph_Microglia.2)
str(Graph_Microglia.3)
str(Graph_MHC.high.Microglia)
```
#Plot VolcanoPlots
```{r}
#For Microglia.1
EnhancedVolcano(Graph_Microglia.1,
                lab = Graph_Microglia.1$gene,
                x = 'log2FoldChange',
                y = 'padj',
                xlim = c(-2, 6),
                ylim = c(0, 3.5),
                pCutoff = 0.05,
                FCcutoff = 2.0,
                pointSize = 3.0,
                labSize = 4.0,
                axisLabSize = 18,
                xlab = bquote(~Log[2] ~ "Fold Change"),
                ylab = bquote(~-Log[10] ~ "Adjusted P-Value"), title = "Microglia.1", legendLabels = c('NS', expression(Log[2]~FC),"Adjusted P-Value", expression(Adjusted~P-Value~and~Log[2]~FC)))
```
#For Microglia.2
```{r}

#For Microglia.2
EnhancedVolcano(Graph_Microglia.2,
                lab = Graph_Microglia.2$gene,
                x = 'log2FoldChange',
                y = 'padj',
                xlim = c(-2, 6),
                ylim = c(0, 5),
                pCutoff = 0.05,
                FCcutoff = 2.0,
                pointSize = 3.0,
                labSize = 4.0,
                axisLabSize = 18,
                xlab = bquote(~Log[2] ~ "Fold Change"),
                ylab = bquote(~-Log[10] ~ "Adjusted P-Value"), title = "Microglia.2", legendLabels = c('NS', expression(Log[2]~FC),"Adjusted P-Value", expression(Adjusted~P-Value~and~Log[2]~FC)))
```

#For Microglia.3

```{r}
#For Microglia.3
EnhancedVolcano(Graph_Microglia.3,
                lab = Graph_Microglia.3$gene,
                x = 'log2FoldChange',
                y = 'padj',
                xlim = c(-2, 6),
                ylim = c(0, 5),
                pCutoff = 0.05,
                FCcutoff = 2.0,
                pointSize = 3.0,
                labSize = 4.0,
                axisLabSize = 18,
                xlab = bquote(~Log[2] ~ "Fold Change"),
                ylab = bquote(~-Log[10] ~ "Adjusted P-Value"), title = "Microglia.3", legendLabels = c('NS', expression(Log[2]~FC),"Adjusted P-Value", expression(Adjusted~P-Value~and~Log[2]~FC)))
```
#MHC high microglia

```{r}
EnhancedVolcano(Graph_MHC.high.Microglia,
                lab = Graph_MHC.high.Microglia$gene,
                x = 'log2FoldChange',
                y = 'padj',
                xlim = c(-2, 6),
                ylim = c(0, 2.5),
                pCutoff = 0.05,
                FCcutoff = 2.0,
                pointSize = 3.0,
                labSize = 4.0,
                axisLabSize = 18,
                xlab = bquote(~Log[2] ~ "Fold Change"),
                ylab = bquote(~-Log[10] ~ "Adjusted P-Value"), title = "MHC high Microglia", legendLabels = c('NS', expression(Log[2]~FC),"Adjusted P-Value", expression(Adjusted~P-Value~and~Log[2]~FC)))


```
#Perform DE by Sample type (all clusters combined)

```{r}
# Aggregate across sample groups
# Using a sample group or individual sample e.g. Fixative.
columnsToUse <- c("Sample", "treatment", "Genotype","Age", "Sex")
colData(sce) <- colData(sce) %>% data.frame() %>% dplyr::select(all_of(columnsToUse)) %>% DataFrame
summed <- aggregateAcrossCells(sce, 
    				id = colData(sce)[,c("Sample")])

# Prep data as before
counts<- counts(summed)
colnames(counts) <- colData(summed)$Sample
summed$treatment <- factor(summed$treatment)
write_rds(summed, "results/1st_Syk_chip/pseudobulk_bysample_singlecellseq_obj.rds")

```

```{r}
dds <- DESeqDataSetFromMatrix(counts(summed), 
                              colData = colData(summed), 
                              design = ~ treatment)


```
#Perform sample level quality control

```{r}
# Transform counts for data visualization
rld <- rlog(dds, blind=TRUE)

# Plot PCA
DESeq2::plotPCA(rld, intgroup = "treatment")

```

```{r}
DESeq2::plotPCA(rld, intgroup = "ncells")
```
#Hierarchical clustering

```{r} 
 # Extract the rlog matrix from the object and compute pairwise correlation values
rld_mat <- assay(rld)
rld_cor <- cor(rld_mat)

# Plot heatmap
pheatmap(rld_cor, annotation = data.frame(colData(summed)[, c("treatment"), drop=F]))
```
#Run DESeq

```{r}
# Run DESeq2 differential expression analysis
dds <- DESeq(dds)
write_rds(dds, "results/1st_Syk_chip/deseq2_pseudobulk_by_sample_combined_clusters_dds.rds")

# Plot dispersion estimates
plotDispEsts(dds)
```
```{r}
# Check the coefficients for the comparison
resultsNames(dds)

# Generate results object
res <- results(dds, 
               name = "treatment_Treated_vs_Control",
               alpha = 0.05)

# Shrink the log2 fold changes to be more appropriate using the apeglm method 
res <- lfcShrink(dds, 
                 coef = "treatment_Treated_vs_Control",
                 res=res,
                 type = "apeglm")


```
#Table of results for all genes
```{r}
# Turn the DESeq2 results object into a tibble for use with tidyverse functions
res_tbl <- res %>%
  data.frame() %>%
  rownames_to_column(var = "gene") %>%
  as_tibble() %>%
  arrange(padj)

# Check results output
res_tbl 

# Write all results to file
write.csv(res_tbl,
          paste0("results/1st_Syk_chip/",  "_pseudobulk_by_Sample_combined_clusters_all_genes.csv"),
          quote = FALSE, 
          row.names = FALSE)



```
#Table of significant genes
```{r}
# Set thresholds
padj_cutoff <- 0.05

# Subset the significant results
sig_res <- dplyr::filter(res_tbl, padj < padj_cutoff) %>%
  dplyr::arrange(padj)

# Check significant genes output
sig_res

# Write significant results to file
write.csv(sig_res,
          paste0("results/1st_Syk_chip/", "_pseudobulk_by_Sample_combined_clusters_signif_genes.csv"),
          quote = FALSE, 
          row.names = FALSE)


```
#Scatterplots
#Top20 p-value

```{r}
## Extract normalized counts from dds object
normalized_counts <- counts(dds, normalized = TRUE)

#Extract top 20 DEG from sing_res by padj (make sure to order by padj)
top20_pvalue <-  sig_res %>% arrange(padj) %>% slice_head(n = 20)
  
#Save top20_pvalue
write.csv(top20_pvalue, paste0("results/1st_Syk_chip/", "_pseudobulk_by_Sample_combined_clusters_top20_pvalue.csv"),
quote = FALSE, row.names = FALSE)
  
## Extract matching normalized count values from matrix
top20_sig_counts <- normalized_counts[rownames(normalized_counts) %in% top20_pvalue$gene, ]
top20_sig_counts

## Convert wide matrix to long data frame for ggplot2
top20_sig_df <- data.frame(top20_sig_counts)
top20_sig_df$gene <- rownames(top20_sig_counts)

top20_sig_df <- melt(setDT(top20_sig_df), 
                     id.vars = c("gene"),
                     variable.name = "Sample") %>% 
  data.frame()


## Join counts data frame with metadata
top20_sig_df <- plyr::join(top20_sig_df, as.data.frame(colData(dds)),
                           by = "Sample")
top20_sig_df

## Generate plot
ggplot(top20_sig_df, aes(y = value, x = treatment, col = treatment)) +
  geom_jitter(height = 0, width = 0.15) +
  scale_y_continuous(trans = 'log10') +
  ylab("log10 of normalized expression level") +
  xlab("condition") +
  ggtitle("Top 20 Significant DE Genes") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ gene)
```
#Combined scatter plot

```{r}

 ## plot using ggplot2
ggplot(top20_sig_df) +
        geom_point(aes(x = gene, 
                       y = value, 
                       color = treatment), 
                   position=position_jitter(w=0.1,h=0)) +
        scale_y_log10() +
        xlab("Genes") +
        ylab("log10 Normalized Counts") +
        ggtitle("Top 20 Significant DE Genes (p-value)") +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
        theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = c("#404040", "#6CA6CD"))

```
#Top20 FC

```{r}

## Extract top 20 DEG from resLFC by FC (make sure to order by FC)
top20_FC <- sig_res %>% arrange(desc(abs(log2FoldChange))) %>% slice_head(n = 20)
  
#Save top20_pvalue
write.csv(top20_FC, paste0("results/1st_Syk_chip/", "pseudobulk_by_Sample_combined_clusters_top20_FC.csv"), quote = FALSE, 
row.names = FALSE)
```


```{r}
## Extract matching normalized count values from matrix
top20_sig_counts <- normalized_counts[rownames(normalized_counts) %in% top20_FC$gene, ]
top20_sig_counts

## Convert wide matrix to long data frame for ggplot2
top20_sig_df <- data.frame(top20_sig_counts)
top20_sig_df$gene <- rownames(top20_sig_counts)

top20_sig_df <- melt(setDT(top20_sig_df), 
                     id.vars = c("gene"),
                     variable.name = "Sample") %>% 
  data.frame()


## Join counts data frame with metadata
top20_sig_df <- plyr::join(top20_sig_df, as.data.frame(colData(dds)),
                           by = "Sample")
top20_sig_df

## Generate plot
ggplot(top20_sig_df, aes(y = value, x = treatment, col = treatment)) +
  geom_jitter(height = 0, width = 0.15) +
  scale_y_continuous(trans = 'log10') +
  ylab("log10 of normalized expression level") +
  xlab("condition") +
  ggtitle("Top 20 Significant DE Genes") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ gene)

```
#Combined scatter plot

```{r}

 ## plot using ggplot2
ggplot(top20_sig_df) +
        geom_point(aes(x = gene, 
                       y = value, 
                       color = treatment), 
                   position=position_jitter(w=0.1,h=0)) +
        scale_y_log10() +
        xlab("Genes") +
        ylab("log10 Normalized Counts") +
        ggtitle("Top 20 Significant DE Genes (FC)") +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
        theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = c("#404040", "#6CA6CD"))

```

#Heatmaps for all significant genes

```{r}
# Extract normalized counts for only the significant genes
sig_counts <- normalized_counts[rownames(normalized_counts) %in% sig_res$gene, ]

# Define the colors
heat_colors <- heat_colors <- rev(brewer.pal(11, "PuOr"))

## Run pheatmap using the metadata data frame for the annotation
pheatmap(sig_counts, 
         color = heat_colors, 
         cluster_rows = TRUE, 
         show_rownames = FALSE,
         annotation = data.frame(colData(summed)[, c("Sample", "treatment")]),
         border_color = NA, 
         fontsize = 10,
         scale = "row", 
         fontsize_row = 10, 
         height = 20)  

```
#Enhanced Volcano

```{r}
#p-value as log
p <- 0.05 
logp <- -log10(p)

combined_clusters <- res_tbl

Graph_combined_clusters <- combined_clusters[c('gene', 'log2FoldChange', 'padj')]
Graph_combined_clusters <-Graph_combined_clusters[!is.na(Graph_combined_clusters$padj), ]

```

```{r}
#Make Numeric if needed
str(Graph_combined_clusters)
```

#Plot VolcanoPlot
```{r}
pdf("results/1st_Syk_chip/Volcanoplot.pdf", width = 5.83, height = 6)
#For Combined Clusters
p <- EnhancedVolcano(Graph_combined_clusters,
                lab = Graph_combined_clusters$gene,
                x = 'log2FoldChange',
                y = 'padj',
                xlim = c(-7, 7),
                ylim = c(0, 13),
                pCutoff = 0.05,
                FCcutoff = 2.0,
                pointSize = 3.0,
                labSize = 4.0,
                axisLabSize = 18,
                xlab = bquote(~Log[2] ~ "Fold Change"),
                ylab = bquote(~-Log[10] ~ "Adjusted P-Value"), title = "Combined clusters", legendLabels = c('NS', expression(Log[2]~FC),"Adjusted P-Value", expression(Adjusted~P-Value~and~Log[2]~FC)))

# Adjust the legend size and position
p <- p + theme(legend.text = element_text(size = 8),  # Adjust the legend text size
legend.title = element_text(size = 10))  # Adjust the legend title size
print(p)
dev.off() 
```
# Pathways

Here we check which pathways the genes we've subset to are associated with.

Note that you can subset to just the biological processes, the cellular component and the molecular function if wanted.
You can chose a different subset by changing the `go_subset` argument to `"CC"` and `"MF"` respectively.

```{r}
## add ensemble ID to pseudo-bulk data
library(gprofiler2)

res <- as.data.frame(res_tbl[which(res_tbl$padj <0.05), ])
# Get the gene symbols from rowData(summed)
gene_symbols <- as.vector(res$gene)

# Perform gene ID conversion using gProfiler for mouse (Mus musculus)
converted_genes <- gconvert(gene_symbols,  organism = "mmusculus", target ="ENSG")

# Create a data frame with Gene_Name and Ensembl_ID
EnsemblID <- data.frame(gene = converted_genes$input, Ensembl_ID = converted_genes$target)

# Merge with the 'res' data frame
res <- merge(res, EnsemblID, by = "gene")

```

```{r}
library(gage)
library(gageData)
## add entrez ids
res$entrez <- mapIds(org.Mm.eg.db, key = res$Ensembl_ID,
                     column = "ENTREZID", keytype = "ENSEMBL",
                     multiVals = "first")

## get fold changes named with respective genes
foldchanges <- res$log2FoldChange
names(foldchanges) <- res$entrez

## get go gage mouse data
data("go.sets.mm")
data("go.subs.mm")

## subset to biological processes
gobpsets <- go.sets.mm[go.subs.mm[["BP"]]]
goccsets <- go.sets.mm[go.subs.mm[["CC"]]]
gomfsets <- go.sets.mm[go.subs.mm[["MF"]]]
gosets <- list("bp" = gobpsets, "cc" = goccsets, "mf" = gomfsets)

gores <- map(gosets, ~ gage(foldchanges, .x, same.dir = T))

## join up and down pathways in one df
pathways <-
  map2(
    gores,
    names(gores),
    ~ cbind(as_tibble(.x$greater, rownames = "pathway"), direction = "greater") %>%
      rbind(cbind(
        as_tibble(.x$less, rownames = "pathway"), direction = "less"
      )) %>%
      ## drop na pvals or pathways
      drop_na(p.val, pathway) %>%
      mutate(pathway_source = .y)
  ) %>%
  ## merge list
  do.call(rbind, .)

rm(go.sets.mm, go.subs.mm, gobpsets, goccsets, gomfsets, gosets, gores)

```
The interactive table shown here is filtered to rows with `p.val < 0.05`.

```{r}
## filter on pvals
pathways_filtered <- pathways[which(pathways$p.val < 0.05), ]

## print interactive table of go pathways
datatable(pathways_filtered, filter = 'top', options = list(pageLength = 5))
## save the filtered pathways
write_csv(pathways_filtered, "results/1st_Syk_chip/go_pathways_combined_clusters_p0.05.csv")
```

#### Inspect GO pathway data

Here we count how many pathways we have for each group with a `p.val < 0.05` and plot the top 10 pathways by `p.val`.

```{r}
## how many significant pathways by group
pathways_filtered %>%
  dplyr::group_by(pathway_source, direction) %>%
  dplyr::summarise(n = n())

## plot top 10 significant pathways for a group
pathways_filtered <- pathways_filtered %>%
  ## add pathways with GO ID (11 characters + a space) stripped out
  dplyr::mutate(pway_stripped = substr(pathway, 12, nchar(pathway))) %>%
  ## sort by p.val
  dplyr::arrange(p.val) %>%
  ## top 10 rows per source
  group_by(pathway_source) %>%
  slice_head(n = 10) %>%
  ungroup() %>%
  ## order data
  dplyr::mutate(pway_stripped = reorder_within(pway_stripped, abs(stat.mean), 
                                               direction))
  ## plot
p1 <- pathways_filtered %>%
  dplyr::filter(pathway_source == "bp") %>%
  ggplot(aes(abs(stat.mean), pway_stripped, fill = direction)) +
  geom_bar(stat="identity") +
  scale_fill_brewer(palette = "Dark2") +
  scale_y_reordered(labels = function(x) str_wrap(str_replace_all(x, "foo" , " "),
                                                 width = 40)) +
  ylab("") +
  xlab("mean") +
  ggtitle("Treated vs Control - top 10 pathways by p.val") +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(~pathway_source, labeller = labeller(pathway_source = c("bp" = "Biological Processes")))

p2 <- pathways_filtered %>%
  dplyr::filter(pathway_source == "cc") %>%
  ggplot(aes(abs(stat.mean), pway_stripped, fill = direction)) +
  geom_bar(stat="identity") +
  scale_fill_brewer(palette = "Dark2") +
  scale_y_reordered(labels = function(x) str_wrap(str_replace_all(x, "foo" , " "),
                                                 width = 40)) +
  ylab("") +
  xlab("mean") +
  ggtitle("Treated vs Control - top 10 pathways by p.val") +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(~pathway_source, labeller = labeller(pathway_source = c("cc" = "Cellular Component")))

p3 <- pathways_filtered %>%
  dplyr::filter(pathway_source == "mf") %>%
  ggplot(aes(abs(stat.mean), pway_stripped, fill = direction)) +
  geom_bar(stat="identity") +
  scale_fill_brewer(palette = "Dark2") +
  scale_y_reordered(labels = function(x) str_wrap(str_replace_all(x, "foo" , " "),
                                                 width = 40)) +
  ylab("") +
  xlab("mean") +
  ggtitle("Treated vs Control - top 10 pathways by p.val") +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(~pathway_source, labeller = labeller(pathway_source = c("mf" = "Molecular function")))

print(p1)
print(p2)




write_rds(pathways_filtered, file = "results/1st_Syk_chip/combined_clusters_go_pathways.rds")
#rm(pathways, p1, p2, pathways_filtered)
```

#KEGG pathways
```{r}
## get kegg data
data(kegg.sets.mm)
## subset of kegg that only contains signalling and metabolic pathways
data(sigmet.idx.mm)

kegg_sets_sub <- kegg.sets.mm[sigmet.idx.mm]

keggres <- gage(foldchanges, gsets = kegg.sets.mm, same.dir = T)

## join up and down pathways in one df
pathways <- cbind(as_tibble(keggres$greater, rownames = "pathway"), 
                  direction = "greater") %>%
      rbind(cbind(as_tibble(keggres$less, rownames = "pathway"), 
                  direction = "less")) %>%
      ## drop na pvals or pathways
      drop_na(p.val, pathway)

rm(kegg.sets.mm, sigmet.idx.mm, kegg_sets_sub, keggres)

```

#Get significant Kegg pathways

```{r}

## filter on pvals
pathways_filtered <- pathways[which(pathways$p.val < 0.2), ]

## print interative table of kegg pathways
datatable(pathways, filter = 'top', options = list(pageLength = 5))
```

The unfiltered KEGG pathways df has `r nrow(pathways)` rows.

#### KEGG visualisation

We can use the `pathview` package to get some nice annotated images of the KEGG pathways.
`pathview` downloads the images, which can take a while, so I've set `eval=FALSE` to not slow down knitr.

```{r}
## save the filtered KEGG pathways
write_csv(pathways_filtered, "results/1st_Syk_chip/KEGG_pathways_combined_clusters_p0.05.csv")

## get kegg pathway ids
## the pathway id is the first 8 characters, subset to these
keggresids <- substr(pathways_filtered$pathway, start = 1, stop = 8)

## subset to foldchanges for relevant comparison

## download images with foldchanges applied

kegg_dir <- setwd("results/1st_Syk_chip/")
tmp <- sapply(keggresids, function(pid) pathview(gene.data = foldchanges,
                                                 pathway.id = pid, species = "mmu",
                                                 kegg.dir = "kegg_dir", out.suffix = "treatment_vs_control"))
## return to prior working dir
setwd("../../")
```
#I can't get the KEGG pathview to work - NEED TO FIX LATER
#ALSO FIX THE edgeR stuff !! (not needed for thesis)

#Differential abundance (DA) analysis

- Looking for per-label/cluster cell abundance across the conditions e.g. is a cell-type enriched in a genotype/treatment.

````{r}
integrated_seurat$idents <- Idents(integrated_seurat)
saveRDS(object = integrated_seurat,"results/1st_Syk_chip/1st_chip_SCTransform_integrated_seurat_withrenamedidents.rds")
abundances <- table(integrated_seurat$idents, integrated_seurat$Sample)
# Unclass to make it a matrix and easier to work with
abundances <- unclass(abundances)
head(abundances)
```
- Preparing the data for DA analysis using `DGEList` function.
  - Add metadata and remove sub-populations with few cells.
  - Note, here the library size is equivalent to the cell number.
  
```{r}

# Attach column metadata if required - I only need treatment
sample_names <- colnames(abundances)
extra.info <- data.frame(treatment = integrated_seurat$treatment[match(sample_names, integrated_seurat$Sample)],
                         sample = sample_names)
```

```{r}
y.ab <- DGEList(abundances, samples = extra.info)

# Remove sub-populations that have very few cells
keep <- filterByExpr(y.ab, group = y.ab$samples)
y.ab <- y.ab[keep,]
summary(keep)
y.ab
```
- Run the EdgeR pipeline, adapt the design matrix to suit your experiment.

- The additional normalisation step is not performed in DA analysis.

- You can also use the `summary()` function to look at the common dispersions and fitted values.

- The QL dispersions graph highlights the raw data (black) and the transformed values (red) that have been moved towards the trendline (blue) based on the whole dataset.

- Output also includes a summary of the clusters, a down-regulation indicates a cluster is less represented in other sample types, an up-regulation indicates an abundance in that sample group compared to others.

- The `topTags(res)` command shows the logFC for the number of cells, providing further information about the differential abundance.

```{r}

# Make the design matrix
design <- model.matrix(~ treatment, y.ab$samples)

```
We use the estimateDisp() function to estimate the NB dispersion for each cluster. We turn off the trend as we do not have enough points for its stable estimation.

```{r}
# Look at NB with 'estimateDisp'
y.ab <- estimateDisp(y.ab, design, trend = "none", robust = TRUE)
summary(y.ab$common.dispersion)
```

```{r}

# Estimate the QL dispersion
fit.ab <- glmQLFit(y.ab, design, robust = TRUE, abundance.trend = FALSE)
summary(fit.ab$var.prior)
```
```{r}
summary(fit.ab$df.prior)
```


```{r}
# Plot Quasi-likelihood Dispersions
plotQLDisp(fit.ab, cex=1)
```
DA
```{r}
# Test for differences in abundance between sample groups
res <- glmQLFTest(fit.ab, coef = ncol(design))

# Summary of results
summary(decideTests(res))
topTags(res)
```

## Investigating composition effects

- In the above analysis the cell numbers are normalised based on the total number of cells in each sample i.e. the percentage.
- There is some risk that this could cause issues in situations where one cell population has a large increase in abundance, making it seem like the other populations in that sample are reduced when in fact they have a similar abundance.
- Therefore, if you can assume that most cell-types do not change in abundance in your model you can use the `calcNormFactors()` function to get normalisation factors before EdgeR analysis.

```{r}
y.ab2 <- calcNormFactors(y.ab)
y.ab2$samples$norm.factors
```
Note - A shift of positive log-fold changes towards zero is consistent with the removal of composition biases.

```{r}
y.ab2 <- estimateDisp(y.ab2, design, trend="none")
fit.ab2 <- glmQLFit(y.ab2, design, robust=TRUE, abundance.trend=FALSE)
res2 <- glmQLFTest(fit.ab2, coef=ncol(design))
# Summary of results
summary(decideTests(res2))
topTags(res2)
```
There are no significant DA clusters between treatment and control

#Clustering independent DA
Other methods like miloR investigate DA without relying on the cluster information but using k-nearest neighbour graph, means the analysis wonâ€™t need to be re-run if clustering is updated.

```{r}
library(miloR)
#Create milo object - needs to be converted into sce 1st

integrated_sce <- as.SingleCellExperiment(integrated_seurat)
Syk_milo <- Milo(integrated_sce)
```
#Preprocessing - DA analysis we need to construct an undirected KNN graph of single-cells. Standard single-cell analysis pipelines usually do this from distances in PCA. We normalize and calculate principal components using scater. I also run UMAP for visualization purposes
```{r}

Syk_milo <- runPCA(Syk_milo, ncomponents=50)
Syk_milo <- runUMAP(Syk_milo)

plotUMAP(Syk_milo)
```
#Build KKN graph

```{r}
Syk_milo <- buildGraph(Syk_milo, k = 10, d = 30)

```

```{r}
Syk_milo <- makeNhoods(Syk_milo, prop = 0.1, k = 50, d=30, refined = TRUE)

```
- Once neighbourhoods are defined, itâ€™s good to take a look at how big the neighbourhoods are (i.e. how many cells form each neighbourhood). This affects the power of DA testing. 
- Itâ€™s best to have a distribution peaking between 50 and 100. 
- If not rerunmakeNhoods increasing k and/or prop 

```{r}

plotNhoodSizeHist(Syk_milo)
```
This looks like this cause it's a small dataset

#Count cells in neighbourhoods

```{r}

Syk_milo <- countCells(Syk_milo, meta.data = data.frame(colData(Syk_milo)), sample="Sample")

```

```{r}
head(nhoodCounts(Syk_milo))

```
Prepare for DA analysis

```{r}
design <- data.frame(colData(Syk_milo))[,c("Sample", "treatment")]
design <- distinct(design)

design
```

```{r}
Syk_milo <- calcNhoodDistance(Syk_milo, d=30)

```

```{r}
rownames(design) <- design$Sample
da_results <- testNhoods(Syk_milo, design = ~ treatment, design.df = design)
```

```{r}
da_results %>%
  arrange(- SpatialFDR) %>%
  head()
```
#Visualize neighbourhoods displaying DA
```{r}
Syk_milo <- buildNhoodGraph(Syk_milo)
plotUMAP(Syk_milo) + plotNhoodGraphDA(Syk_milo, da_results, alpha=0.05) +
  plot_layout(guides="collect")

```
